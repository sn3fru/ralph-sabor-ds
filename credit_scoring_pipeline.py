#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Credit Scoring Pipeline - Script Python
Converte o notebook Jupyter em script execut√°vel com logging markdown estruturado
para an√°lise por LLMs.
"""

import sys
import os
import json
from pathlib import Path
import yaml

# Configurar encoding UTF-8 para stdout no Windows
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Machine Learning
from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold
from sklearn.metrics import (
    roc_auc_score, roc_curve, confusion_matrix, 
    classification_report, precision_recall_curve
)
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import StandardScaler

# An√°lise de Drift
try:
    from scipy import stats
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from sklearn.manifold import TSNE
    from sklearn.decomposition import PCA
    SKLEARN_FULL_AVAILABLE = True
except ImportError:
    SKLEARN_FULL_AVAILABLE = False

# Modelos
import xgboost as xgb

# Explainability
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False

# Otimiza√ß√£o
try:
    import optuna
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False

# Configura√ß√µes de plotagem
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 11

# Importar m√≥dulos customizados
sys.path.insert(0, str(Path(__file__).parent / 'src'))
try:
    from src import (
        temporal_cross_validation,
        adversarial_validation_temporal,
        calibrate_model,
        find_optimal_threshold,
        evaluate_financial_impact,
        monitor_drift
    )
except ImportError as e:
    print(f"[WARN] Erro ao importar utilitarios: {e}")

# Importar logger markdown
from markdown_logger import MarkdownLogger

# =============================================================================
# FUN√á√ïES AUXILIARES PARA ENRIQUECIMENTO DE CONTEXTO
# =============================================================================

def simulate_auc_elasticity(y_true, y_best_proba, cost_matrix, fixed_threshold, n_steps=50, random_seed=42):
    """
    Simula a degrada√ß√£o da AUC misturando o modelo atual com ru√≠do aleat√≥rio
    e mede o impacto no lucro mantendo o threshold fixo.
    
    Args:
        y_true: Labels verdadeiros
        y_best_proba: Probabilidades do melhor modelo
        cost_matrix: Dicion√°rio com custos {'tp': 1500, 'fp': -10000, 'fn': 0, 'tn': 0}
        fixed_threshold: Threshold fixo para aplicar em todas as simula√ß√µes
        n_steps: N√∫mero de pontos na simula√ß√£o (default: 50)
        random_seed: Seed para reprodutibilidade
    
    Returns:
        DataFrame com colunas: noise_alpha, auc, profit
    """
    results = []
    
    # Gerar ru√≠do base (aleat√≥rio uniforme) uma vez
    np.random.seed(random_seed)
    noise_base = np.random.rand(len(y_true))
    
    # Iterar de 0% de ru√≠do (Modelo Atual) at√© 100% (Aleat√≥rio)
    alphas = np.linspace(0, 1.0, n_steps)
    
    for alpha in alphas:
        # Mistura linear: (1-alpha)*Modelo + alpha*Ru√≠do
        # Isso degrada a qualidade da ordena√ß√£o suavemente
        y_simulated = (1 - alpha) * y_best_proba + alpha * noise_base
        
        # Recalcular AUC
        try:
            sim_auc = roc_auc_score(y_true, y_simulated)
        except ValueError:
            # Se AUC n√£o puder ser calculada (ex: todas as classes iguais), pular
            continue
        
        # Aplicar Threshold Fixo
        preds = (y_simulated >= fixed_threshold).astype(int)
        
        # Calcular Lucro
        cm = confusion_matrix(y_true, preds)
        if cm.size == 4:
            tn, fp, fn, tp = cm.ravel()
        else:
            # Caso especial: matriz 1x1 ou 2x1
            continue
        
        profit = (tp * cost_matrix.get('tp', 0)) + (fp * cost_matrix.get('fp', 0)) + \
                 (fn * cost_matrix.get('fn', 0)) + (tn * cost_matrix.get('tn', 0))
        
        results.append({
            'noise_alpha': alpha,
            'auc': sim_auc,
            'profit': profit
        })
        
    return pd.DataFrame(results)


def calculate_elasticity_coefficient(df_results):
    """
    Calcula a elasticidade m√©dia via Regress√£o Linear (Slope).
    
    Returns:
        elasticity_coef: Coeficiente de elasticidade
        df_reg: DataFrame usado para regress√£o (faixa √∫til)
    """
    if len(df_results) == 0:
        return 0.0, df_results
    
    # Focamos na metade superior da performance (onde o modelo √© √∫til)
    # Elasticidade = % Varia√ß√£o Lucro / % Varia√ß√£o AUC
    df_reg = df_results[df_results['auc'] > 0.65].copy()
    
    if len(df_reg) < 5:  # M√≠nimo de pontos para regress√£o
        df_reg = df_results.copy()
    
    if len(df_reg) == 0:
        return 0.0, df_results
    
    base_profit = df_reg['profit'].min()
    
    if base_profit <= 0 or df_reg['profit'].std() == 0:
        # Se lucro for negativo ou constante, usamos escala linear simples
        X = df_reg[['auc']].values
        y = df_reg['profit'].values
    else:
        # Elasticidade Log-Log (Econometria Cl√°ssica)
        # Evitar log de valores negativos ou zero
        df_reg_clean = df_reg[df_reg['auc'] > 0.01].copy()
        df_reg_clean = df_reg_clean[df_reg_clean['profit'] > 0.01].copy()
        
        if len(df_reg_clean) < 5:
            X = df_reg[['auc']].values
            y = df_reg['profit'].values
        else:
            X = np.log(df_reg_clean[['auc']].values)
            y = np.log(df_reg_clean['profit'].values)
            df_reg = df_reg_clean
    
    if len(X) == 0:
        return 0.0, df_results
    
    try:
        from sklearn.linear_model import LinearRegression
        model = LinearRegression()
        model.fit(X, y)
        elasticity_coef = model.coef_[0] if len(model.coef_) > 0 else 0.0
    except:
        elasticity_coef = 0.0
    
    return elasticity_coef, df_reg

def calculate_max_potential_profit(y_true, cost_matrix):
    """
    Calcula o lucro m√°ximo te√≥rico (Bola de Cristal Perfeita).
    
    O lucro m√°ximo seria se tiv√©ssemos um modelo perfeito que:
    - Aprova todos os bons pagadores (y=1) -> Ganho TP
    - Rejeita todos os caloteiros (y=0) -> Ganho TN (geralmente 0)
    
    Args:
        y_true: Array com labels verdadeiros (0 ou 1)
        cost_matrix: Dict com custos {'tp': 1500, 'fp': -10000, 'fn': 0, 'tn': 0}
    
    Returns:
        float: Lucro m√°ximo te√≥rico poss√≠vel
    """
    n_positives = np.sum(y_true == 1)  # Bons pagadores
    n_negatives = np.sum(y_true == 0)  # Maus pagadores
    
    # Com modelo perfeito:
    # - Aprovamos todos os 1 (ganhamos TP * n_positives)
    # - Rejeitamos todos os 0 (ganhamos TN * n_negatives, geralmente 0)
    max_profit = (n_positives * cost_matrix.get('tp', 0)) + (n_negatives * cost_matrix.get('tn', 0))
    
    return max_profit


def calculate_psi(expected, actual, bins=10, buckettype='bins'):
    """
    Calcula o Population Stability Index (PSI) de forma robusta.
    
    Args:
        expected: Distribui√ß√£o esperada (treino)
        actual: Distribui√ß√£o atual (produ√ß√£o)
        bins: N√∫mero de bins para discretiza√ß√£o
        buckettype: Tipo de discretiza√ß√£o ('bins' ou 'quantiles')
    
    Returns:
        float: Valor do PSI
    """
    # Determinar breakpoints baseado no tipo
    if buckettype == 'bins':
        breakpoints = np.linspace(
            min(np.min(expected), np.min(actual)),
            max(np.max(expected), np.max(actual)),
            bins + 1
        )
    elif buckettype == 'quantiles':
        percentiles = np.arange(0, bins + 1) / bins * 100
        breakpoints = np.array([np.percentile(expected, p) for p in percentiles])
    else:
        # Default: bins
        breakpoints = np.linspace(
            min(np.min(expected), np.min(actual)),
            max(np.max(expected), np.max(actual)),
            bins + 1
        )

    # Calcular distribui√ß√µes
    expected_percents = np.histogram(expected, bins=breakpoints)[0] / len(expected)
    actual_percents = np.histogram(actual, bins=breakpoints)[0] / len(actual)

    # Evita divis√£o por zero (clipping m√≠nimo)
    expected_percents = np.clip(expected_percents, 0.0001, 1.0)
    actual_percents = np.clip(actual_percents, 0.0001, 1.0)

    # Calcular PSI
    psi_value = np.sum((actual_percents - expected_percents) * np.log(actual_percents / expected_percents))
    return psi_value


def describe_curve_geometry_robust(x, y, name="Curva"):
    """
    An√°lise geom√©trica robusta a ru√≠do e degraus iniciais.
    Usa janela de an√°lise em vez de apenas 2 pontos para evitar falsos zeros.
    
    Args:
        x: Valores do eixo X
        y: Valores do eixo Y
        name: Nome da curva
    
    Returns:
        Descri√ß√£o textual da geometria da curva com an√°lise estat√≠stica
    """
    if len(x) < 5 or len(y) < 5:
        return f"{name}: Dados insuficientes para an√°lise robusta (m√≠nimo 5 pontos)."
    
    # 1. An√°lise de Tend√™ncia Inicial (Janela de 5% dos dados ou m√≠nimo 5 pontos)
    # Isso evita falsos zeros quando y[0] == y[1] por precis√£o ou ru√≠do
    window = max(5, int(len(x) * 0.05))
    
    # Delta Y no in√≠cio (Robustez contra y[0]==y[1])
    dy_start = y[window] - y[0]
    dx_start = x[window] - x[0]
    
    if dx_start == 0:
        slope_metric = 0
    else:
        slope_metric = dy_start / dx_start
    
    # Classifica√ß√£o da inclina√ß√£o inicial
    if slope_metric > 1.0:
        slope_desc = "Crescimento Agressivo (Excelente)"
    elif slope_metric > 0.5:
        slope_desc = "Crescimento Moderado (Bom)"
    elif slope_metric > 0.1:
        slope_desc = "Crescimento Lento (Alerta)"
    elif slope_metric > -0.1:
        slope_desc = "Estagnado/Plano (Cr√≠tico)"
    else:
        slope_desc = "Decl√≠nio Inicial (An√¥malo)"
    
    # 2. Detec√ß√£o de "Cotovelo" (Ponto onde o ganho marginal diminui)
    # Onde a curva atinge 80% do m√°ximo
    try:
        y_max = np.max(y)
        idx_80 = np.where(y >= y_max * 0.8)[0]
        if len(idx_80) > 0:
            x_80 = x[idx_80[0]]
            elbow_desc = f"Atinge 80% da performance em x={x_80:.3f}"
        else:
            elbow_desc = "N√£o atinge 80% do pico"
    except:
        elbow_desc = "An√°lise de cotovelo indispon√≠vel"
    
    # 3. An√°lise de estabilidade (zona plana no topo)
    y_threshold = y_max * 0.95  # 95% do m√°ximo
    flat_zone_indices = np.where(y >= y_threshold)[0]
    
    if len(flat_zone_indices) > 1:
        flat_zone_start = x[flat_zone_indices[0]]
        flat_zone_end = x[flat_zone_indices[-1]]
        flat_zone_width = flat_zone_end - flat_zone_start
        flat_desc = f"Zona est√°vel (95% do pico) entre x={flat_zone_start:.3f} e x={flat_zone_end:.3f} (largura={flat_zone_width:.3f})"
    else:
        flat_desc = "Sem zona est√°vel significativa no topo"
    
    # 4. Pico da curva
    peak_idx = np.argmax(y)
    peak_x = x[peak_idx]
    peak_y = y[peak_idx]
    
    return (
        f"**Geometria da {name}:**\n"
        f"- **Comportamento Inicial (Janela {window} pts):** {slope_desc} (Slope={slope_metric:.3f}).\n"
        f"- **Efici√™ncia:** {elbow_desc}.\n"
        f"- **Estabilidade:** {flat_desc}.\n"
        f"- **Pico:** x={peak_x:.3f}, y={peak_y:.3f}."
    )

# Mant√©m fun√ß√£o antiga para compatibilidade (deprecated)
def describe_curve_geometry(x, y, name="Curva"):
    """Deprecated: Use describe_curve_geometry_robust."""
    return describe_curve_geometry_robust(x, y, name)
    
    description = (
        f"**An√°lise geom√©trica da {name}:**\n\n"
        f"- **Pico:** Ocorre em x={peak_x:.3f} com valor y={peak_y:.3f}\n"
        f"- **Crescimento inicial:** {slope_desc} (inclina√ß√£o inicial: {slope_start:.3f})\n"
    )
    
    if has_flat_zone:
        description += (
            f"- **Zona de estabilidade:** A curva apresenta uma regi√£o plana (flat-top) "
            f"entre x={flat_zone_start:.3f} e x={flat_zone_end:.3f} (largura: {flat_zone_width:.3f}). "
            f"Isso indica que o modelo √© robusto a varia√ß√µes nesta faixa.\n"
        )
    
    description += f"- **Decl√≠nio ap√≥s pico:** {decline_desc}\n"
    
    return description

def generate_dynamic_insight(feature_name, null_percent, logger):
    """
    Gera insight din√¢mico baseado nos dados reais da rodada.
    
    Args:
        feature_name: Nome da feature
        null_percent: Percentual de nulos
        logger: Inst√¢ncia do logger
    """
    if null_percent > 90:
        insight = (
            f"A feature {feature_name} tem {null_percent:.1f}% de valores nulos. "
            "Devido √† alta cardinalidade de nulos, o XGBoost provavelmente est√° usando "
            "essa aus√™ncia como uma categoria informativa (ex: cliente sem hist√≥rico espec√≠fico). "
            "Esta feature pode estar capturando padr√µes de 'novos clientes' ou 'dados n√£o coletados'."
        )
    elif null_percent > 50:
        insight = (
            f"A feature {feature_name} tem {null_percent:.1f}% de valores nulos. "
            "Este alto percentual sugere que a feature pode ser condicionalmente relevante "
            "(s√≥ existe para um subconjunto de clientes). O XGBoost pode estar usando "
            "a presen√ßa/aus√™ncia desta feature como um sinal importante."
        )
    else:
        insight = (
            f"A feature {feature_name} tem {null_percent:.1f}% de valores nulos. "
            "Percentual moderado que n√£o compromete a utilidade da feature."
        )
    
    return insight

# =============================================================================
# CONFIGURA√á√ÉO INICIAL
# =============================================================================

def rollback_config(config_path: Path, backup_path: Path):
    """
    ‚úÖ 3. ROLLBACK AUTOM√ÅTICO: Restaura config.yaml do backup em caso de falha cr√≠tica.
    """
    if backup_path.exists() and config_path.exists():
        try:
            import shutil
            shutil.copy(backup_path, config_path)
            print(f"[ROLLBACK] Config.yaml restaurado do backup devido a falha critica.")
            return True
        except Exception as e:
            print(f"[ERRO] Falha ao restaurar backup: {e}")
            return False
    return False

def main():
    """Fun√ß√£o principal que executa todo o pipeline."""
    
    # ‚úÖ 1. CARREGAR CONFIGURA√á√ÉO COMPLETA DO config.yaml
    config_path = Path(__file__).parent / "config.yaml"
    config_backup_path = Path(__file__).parent / "config.yaml.backup"
    
    # Backup do config antes de qualquer modifica√ß√£o (para rollback)
    if config_path.exists() and not config_backup_path.exists():
        try:
            import shutil
            shutil.copy(config_path, config_backup_path)
            print(f"[INFO] Backup do config.yaml criado: {config_backup_path}")
        except Exception as e:
            print(f"[WARN] Nao foi possivel criar backup do config: {e}")
    
    # ‚úÖ 4. VISUALIZA√á√ÉO EM TEMPO REAL: Progress bar simples
    import sys
    def print_progress(step: str, current: int = 0, total: int = 0):
        """Imprime progresso em tempo real."""
        if total > 0:
            percent = int((current / total) * 100)
            bar_length = 30
            filled = int(bar_length * current / total)
            bar = '=' * filled + '-' * (bar_length - filled)
            sys.stdout.write(f'\r[{step}] [{bar}] {percent}% ({current}/{total})')
            sys.stdout.flush()
        else:
            sys.stdout.write(f'\r[{step}] ...')
            sys.stdout.flush()
    
    try:
        config = {}
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f) or {}
                print("[OK] Config.yaml carregado com sucesso")
            except Exception as e:
                print(f"[ERRO] Erro ao ler config.yaml: {e}. Usando valores padrao.")
                config = {}
        
        # Extrair configura√ß√µes com valores padr√£o
        pipeline_config = config.get('pipeline', {})
        MODO = pipeline_config.get('mode', 'DEV').upper()
        RUN_SHAP = pipeline_config.get('run_shap', False)
        
        xgboost_config = config.get('xgboost_params', {})
        feature_config = config.get('feature_selection', {})
        business_config = config.get('business_params', {})
        
        # Configura√ß√£o de Vision LLM (an√°lise visual autom√°tica)
        # Tenta carregar do arquivo .env primeiro
        def load_env_file(env_path: Path) -> dict:
            """Carrega vari√°veis de um arquivo .env."""
            env_vars = {}
            if env_path.exists():
                try:
                    with open(env_path, 'r', encoding='utf-8') as f:
                        for line in f:
                            line = line.strip()
                            if line and not line.startswith('#') and '=' in line:
                                key, value = line.split('=', 1)
                                key = key.strip()
                                value = value.strip().strip('"').strip("'")  # Remove aspas
                                env_vars[key] = value
                except Exception as e:
                    print(f"[WARN] Erro ao ler arquivo .env: {e}")
            return env_vars
        
        # Carregar vari√°veis do .env
        env_path = Path(__file__).parent / '.env'
        env_vars = load_env_file(env_path)
        
        # Determina API key: .env > vari√°veis de ambiente
        vision_api_key = None
        vision_provider = None
        vision_model_name = None
        
        # Prioridade: .env primeiro, depois vari√°veis de ambiente
        if "GEMINI_KEY" in env_vars:
            vision_api_key = env_vars["GEMINI_KEY"]
            vision_provider = "gemini"
            vision_model_name = env_vars.get("MODEL_NAME", "gemini-1.5-pro")
            print(f"[OK] Configuracao carregada do .env: Gemini (Modelo: {vision_model_name})")
        elif os.getenv("OPENAI_API_KEY"):
            vision_api_key = os.getenv("OPENAI_API_KEY")
            vision_provider = "openai"
        elif os.getenv("GEMINI_API_KEY"):
            vision_api_key = os.getenv("GEMINI_API_KEY")
            vision_provider = "gemini"
            vision_model_name = env_vars.get("MODEL_NAME", "gemini-1.5-pro")
        elif os.getenv("ANTHROPIC_API_KEY"):
            vision_api_key = os.getenv("ANTHROPIC_API_KEY")
            vision_provider = "claude"
        else:
            vision_provider = "openai"  # Default (mas n√£o ser√° usado se n√£o houver API key)
        
        use_vision = vision_api_key is not None
        
        # Inicializar logger markdown com suporte a an√°lise visual
        logger = MarkdownLogger(
            output_dir="reports",
            use_vision_llm=use_vision,
            vision_provider=vision_provider,
            vision_api_key=vision_api_key,
            vision_model_name=vision_model_name  # Passa o model_name do .env
        )
        
        logger.section("Credit Scoring: Maquina de Decisao de Credito", level=1)
        logger.log("Pipeline de analise executiva de risco de credito com Machine Learning", "info")
        logger.log(f"Modo de execucao: {MODO}", "info")
        
        # ‚úÖ Log das configura√ß√µes carregadas do config.yaml
        logger.section("0. Configuracao do Pipeline", level=2)
        logger.log(f"Modo: {MODO}", "info")
        logger.log(f"SHAP: {'Ativado' if RUN_SHAP else 'Desativado'}", "info")
        logger.log(f"Correlation Threshold: {feature_config.get('correlation_threshold', 0.95)}", "info")
        logger.log(f"Max Depth: {xgboost_config.get('max_depth', 6)}", "info")
        logger.log(f"Learning Rate: {xgboost_config.get('learning_rate', 0.05)}", "info")
        logger.log(f"N Estimators ({MODO}): {xgboost_config.get(f'n_estimators_{MODO.lower()}', 50 if MODO == 'DEV' else 500)}", "info")
        
        # =============================================================================
        # 1. SETUP & INFRAESTRUTURA
        # =============================================================================
        
        logger.section("1. Setup & Infraestrutura", level=2)
        
        # Verifica√ß√£o de GPU
        try:
            import subprocess
            result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
            GPU_AVAILABLE = result.returncode == 0
            if GPU_AVAILABLE:
                logger.log("GPU NVIDIA detectada - XGBoost pode usar acelera√ß√£o GPU", "success")
            else:
                logger.log("GPU n√£o detectada - usando CPU", "warning")
                GPU_AVAILABLE = False
        except:
            GPU_AVAILABLE = False
            logger.log("GPU n√£o detectada - usando CPU", "warning")
        
        logger.log_metric("Pandas Version", pd.__version__)
        logger.log_metric("NumPy Version", np.__version__)
        logger.log_metric("XGBoost Version", xgb.__version__)
        logger.log_metric("GPU Available", GPU_AVAILABLE)
        
        # =============================================================================
        # 2. ENGENHARIA DE DADOS
        # =============================================================================
        
        logger.section("2. Engenharia de Dados", level=2)
        
        logger.log("Carregando arquivos parquet...", "info")
        
        # Carregar dados
        df_train_raw = pd.read_parquet('train.parquet')
        df_test_raw = pd.read_parquet('test.parquet')
    
        logger.log_metric("Train Raw Shape (Original)", f"{df_train_raw.shape[0]:,} linhas √ó {df_train_raw.shape[1]} colunas")
        logger.log_metric("Test Raw Shape (Original)", f"{df_test_raw.shape[0]:,} linhas √ó {df_test_raw.shape[1]} colunas")
        
        # ‚úÖ AMOSTRAGEM NO MODO DEV: Reduzir dados para desenvolvimento r√°pido
        DEV_SAMPLE_SIZE = 10000  # ~10k linhas no modo DEV
        train_original_size = len(df_train_raw)  # Guardar tamanho original
        
        if MODO == 'DEV' and len(df_train_raw) > DEV_SAMPLE_SIZE:
            logger.log(f"[DEV MODE] Aplicando amostragem estratificada de {DEV_SAMPLE_SIZE:,} linhas para acelerar desenvolvimento...", "info")
            
            # Amostragem estratificada do treino (mant√©m propor√ß√£o de classes)
            if 'label' in df_train_raw.columns and df_train_raw['label'].notna().sum() > 0:
                from sklearn.model_selection import train_test_split
                # Garantir que temos amostras suficientes de cada classe
                label_counts = df_train_raw['label'].value_counts()
                min_samples_per_class = label_counts.min() if len(label_counts) > 0 else 0
                
                # Calcular tamanho da amostra (garantir pelo menos algumas amostras de cada classe)
                sample_size = min(DEV_SAMPLE_SIZE, len(df_train_raw))
                
                if sample_size < len(df_train_raw) and min_samples_per_class > 10:
                    # Amostragem estratificada
                    df_train_raw, _ = train_test_split(
                        df_train_raw,
                        train_size=sample_size,
                        stratify=df_train_raw['label'],
                        random_state=42
                    )
                    logger.log(f"[DEV MODE] Treino reduzido para {len(df_train_raw):,} linhas (amostragem estratificada)", "info")
                elif sample_size < len(df_train_raw):
                    # Amostragem simples se n√£o conseguir estratificar
                    df_train_raw = df_train_raw.sample(n=sample_size, random_state=42)
                    logger.log(f"[DEV MODE] Treino reduzido para {len(df_train_raw):,} linhas (amostragem aleatoria)", "info")
            else:
                # Se n√£o tem label, faz sample simples
                df_train_raw = df_train_raw.sample(n=min(DEV_SAMPLE_SIZE, len(df_train_raw)), random_state=42)
                logger.log(f"[DEV MODE] Treino reduzido para {len(df_train_raw):,} linhas (amostragem aleatoria)", "info")
            
            # Amostragem do teste (proporcional ao treino)
            reduction_ratio = len(df_train_raw) / train_original_size if train_original_size > 0 else 1.0
            test_sample_size = min(
                int(len(df_test_raw) * reduction_ratio),
                len(df_test_raw),
                DEV_SAMPLE_SIZE // 2  # Teste menor que treino
            )
            
            if test_sample_size < len(df_test_raw):
                df_test_raw = df_test_raw.sample(n=test_sample_size, random_state=42)
                logger.log(f"[DEV MODE] Teste reduzido para {len(df_test_raw):,} linhas", "info")
            
            logger.log_metric("Train Raw Shape (Apos Sampling)", f"{df_train_raw.shape[0]:,} linhas")
            logger.log_metric("Test Raw Shape (Apos Sampling)", f"{df_test_raw.shape[0]:,} linhas")
            logger.log_insight(
                f"Modo DEV ativo: usando amostra de {len(df_train_raw):,} linhas de treino e {len(df_test_raw):,} linhas de teste "
                f"para desenvolvimento rapido. Execute em modo PROD para usar dataset completo ({train_original_size:,} linhas).",
                "dev_mode"
            )
        
        # Harmoniza√ß√£o
        df_test_raw['label'] = np.nan
        if 'split' not in df_test_raw.columns:
            df_test_raw['split'] = 'test'
        df_train_raw['dataset_origin'] = 'train_file'
        df_test_raw['dataset_origin'] = 'test_file_blind'
        
        # Master Table
        df_full = pd.concat([df_train_raw, df_test_raw], axis=0, ignore_index=True)
        df = df_full
        
        logger.log_metric("DataFrame Unificado", f"{df_full.shape[0]:,} linhas √ó {df_full.shape[1]} colunas")
        logger.log_metric("Com Label", f"{df_full['label'].notna().sum():,}")
        logger.log_metric("Sem Label", f"{df_full['label'].isna().sum():,}")
        
        # Split temporal
        df_modeling = df_full[df_full['dataset_origin'] == 'train_file'].copy()
        feature_cols = [col for col in df_modeling.columns if col.startswith('feature_')]
        X = df_modeling[feature_cols]
        y = df_modeling['label']
        
        split_idx = int(len(X) * 0.80)
        X_train = X.iloc[:split_idx]
        X_val = X.iloc[split_idx:]
        y_train = y.iloc[:split_idx]
        y_val = y.iloc[split_idx:]
        
        df_test_for_drift = df_full[df_full['dataset_origin'] == 'test_file_blind'].copy()
        df_train_for_drift = df_full[df_full['dataset_origin'] == 'train_file'].copy()  # ‚úÖ Adicionado para an√°lise de drift
        X_test_blind = df_test_for_drift[feature_cols].copy()
        
        logger.log_metric("Treino", f"{X_train.shape[0]:,} amostras")
        logger.log_metric("Valida√ß√£o", f"{X_val.shape[0]:,} amostras")
        logger.log_metric("Teste Cego", f"{X_test_blind.shape[0]:,} amostras")
        logger.log_metric("Features", len(feature_cols))
        
        # ‚úÖ INJE√á√ÉO DE CONTEXTO GLOBAL: Setup de Dados
        logger.update_context("n_samples_train", len(X_train))
        logger.update_context("n_samples_val", len(X_val))
        logger.update_context("n_samples_test", len(X_test_blind))
        logger.update_context("n_features_raw", len(feature_cols))
        
        # =============================================================================
        # 3. EDA EXECUTIVA
        # =============================================================================
        
        logger.section("3. EDA Executiva", level=2)
        
        # Auditoria de integridade
        logger.log(f"Dimens√µes: {df.shape[0]:,} linhas √ó {df.shape[1]} colunas", "info")
        logger.log_metric("Mem√≥ria utilizada", f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # Distribui√ß√£o da target
        if 'label' in df.columns:
            target_dist = df['label'].value_counts()
            balance_ratio = target_dist.min() / target_dist.max()
            
            logger.log_table("Distribui√ß√£o da Target", {
                'Classe 0': int(target_dist.get(0, 0)),
                'Classe 1': int(target_dist.get(1, 0)),
                'Taxa de Balanceamento': f"{balance_ratio:.3f}"
            })
            
            # ‚úÖ INJE√á√ÉO DE CONTEXTO GLOBAL: Balanceamento
            logger.update_context("class_balance_ratio", balance_ratio)
            logger.update_context("target_imbalance_status", "Severe" if balance_ratio < 0.1 else "Moderate" if balance_ratio < 0.3 else "Balanced")
            logger.update_context("class_0_count", int(target_dist.get(0, 0)))
            logger.update_context("class_1_count", int(target_dist.get(1, 0)))
            
            if balance_ratio < 0.3:
                logger.log("PROBLEMA DESBALANCEADO - Necess√°rio ajuste de estrat√©gia de modelagem", "warning")
                logger.log_insight(
                    f"O dataset est√° severamente desbalanceado (raz√£o {balance_ratio:.3f}). "
                    "Ser√° necess√°rio usar scale_pos_weight no XGBoost para compensar.",
                    "overfitting"
                )
        
        # An√°lise de valores nulos
        null_percent = df[feature_cols].isnull().sum() / len(df) * 100
        null_summary = null_percent.sort_values(ascending=False)
        
        logger.log_table("Top 10 Features com Mais Nulos", 
                         {k: f"{v:.2f}%" for k, v in null_summary.head(10).items()})
        
        logger.log_metric("Features com 0% nulos", (null_percent == 0).sum())
        logger.log_metric("Features com >0% e ‚â§10% nulos", ((null_percent > 0) & (null_percent <= 10)).sum())
        logger.log_metric("Features com >10% e ‚â§50% nulos", ((null_percent > 10) & (null_percent <= 50)).sum())
        logger.log_metric("Features com >50% nulos", (null_percent > 50).sum())
        
        # ‚úÖ MELHORIA: Insights din√¢micos baseados nos dados reais
        top_null_feature = null_summary.index[0]
        top_null_percent = null_summary.iloc[0]
        dynamic_insight = generate_dynamic_insight(top_null_feature, top_null_percent, logger)
        logger.log_insight(dynamic_insight, "data_quality")
        
        # Visualiza√ß√£o de nulos
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        axes[0].hist(null_percent, bins=50, edgecolor='black', alpha=0.7)
        axes[0].axvline(null_percent.median(), color='red', linestyle='--', 
                        label=f'Mediana: {null_percent.median():.2f}%')
        axes[0].set_xlabel('Percentual de Valores Nulos (%)')
        axes[0].set_ylabel('N√∫mero de Features')
        axes[0].set_title('Distribui√ß√£o de Nulos nas Features')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        top_nulls = null_summary.head(15)
        axes[1].barh(range(len(top_nulls)), top_nulls.values, color='coral')
        axes[1].set_yticks(range(len(top_nulls)))
        axes[1].set_yticklabels(top_nulls.index)
        axes[1].set_xlabel('Percentual de Nulos (%)')
        axes[1].set_title('Top 15 Features com Mais Nulos')
        axes[1].grid(True, alpha=0.3, axis='x')
        
        plt.tight_layout()
        
        # Contexto t√©cnico detalhado para an√°lise IA
        null_plot_context = (
            f"Distribui√ß√£o de valores nulos nas {len(feature_cols)} features do dataset de credit scoring. "
            f"Gr√°fico √† esquerda: histograma da distribui√ß√£o de percentuais de nulos (mediana: {null_percent.median():.2f}%). "
            f"Gr√°fico √† direita: top 15 features com maior percentual de nulos (m√°ximo: {null_summary.iloc[0]:.2f}%). "
            f"Total de features com >50% nulos: {(null_percent > 50).sum()}. "
            f"O XGBoost usa sparse-aware split finding para lidar com nulos, tratando aus√™ncia como informa√ß√£o."
        )
        
        logger.log_plot(
            fig,
            title="Distribui√ß√£o de Valores Nulos nas Features",
            description="Distribui√ß√£o de valores nulos nas features",
            context_description=null_plot_context,
            save_image=True,
            analyze=True
        )
        
        logger.log_insight(
            "XGBoost lida nativamente com nulos atrav√©s de 'sparse-aware split finding'. "
            "Isso evita imputa√ß√£o arbitr√°ria e preserva informa√ß√£o de padr√µes de missingness.",
            "geral"
        )
        
        # =============================================================================
        # 3.1. AN√ÅLISE DE DRIFT TEMPORAL COMPLETA (Estat√≠stica + Visual)
        # =============================================================================
        
        logger.section("3.1. An√°lise de Drift Temporal Completa", level=3)
        
        if SCIPY_AVAILABLE and SKLEARN_FULL_AVAILABLE:
            try:
                from matplotlib.lines import Line2D
                
                logger.log("Iniciando an√°lise de drift temporal completa (KS Test + PCA + t-SNE)...", "info")
                
                # Defini√ß√£o dos datasets
                train_df = df_train_for_drift.copy()
                test_df = df_test_for_drift.copy()
                
                logger.log_metric("Treino (Refer√™ncia)", f"{len(train_df):,} amostras")
                logger.log_metric("Teste (Atual/Cego)", f"{len(test_df):,} amostras")
                
                if len(test_df) < 10:
                    logger.log("ALERTA: Base de teste insuficiente (<10 amostras). Pulando an√°lise.", "warning")
                else:
                    # 1. Sele√ß√£o de Features (Top 20 por Vari√¢ncia)
                    numeric_cols = train_df.select_dtypes(include=[np.number]).columns
                    valid_cols = [c for c in feature_cols if c in numeric_cols] if 'feature_cols' in locals() else numeric_cols
                    top_features = train_df[valid_cols].var().sort_values(ascending=False).head(20).index.tolist()
                    
                    logger.log(f"Calculando drift nas top {len(top_features)} features...", "info")
                    
                    # 2. C√ÅLCULO ESTAT√çSTICO (KS TEST)
                    drift_results = []
                    for feat in top_features:
                        train_vals = train_df[feat].dropna()
                        test_vals = test_df[feat].dropna()
                        
                        if len(train_vals) > 10 and len(test_vals) > 10:
                            ks_stat, ks_pvalue = stats.ks_2samp(train_vals, test_vals)
                            drift_results.append({
                                'feature': feat,
                                'ks_statistic': ks_stat,
                                'ks_pvalue': ks_pvalue
                            })
                    
                    drift_df = pd.DataFrame(drift_results).sort_values('ks_statistic', ascending=False)
                    
                    # Exibir Top 10 Drift
                    logger.log_table("Top 10 Features com Maior Instabilidade (KS Statistic)",
                                   {row['feature']: f"KS={row['ks_statistic']:.4f}, p={row['ks_pvalue']:.4f}" 
                                    for _, row in drift_df.head(10).iterrows()})
                    
                    # 3. PREPARA√á√ÉO VISUAL (PCA & t-SNE)
                    logger.log("Processando mapa visual (PCA & t-SNE) com 10k pontos...", "info")
                    
                    n_sample = min(len(train_df), len(test_df), 5000)
                    
                    df_train_sample = train_df[top_features].sample(n=n_sample, random_state=42).fillna(0)
                    df_test_sample = test_df[top_features].sample(n=n_sample, random_state=42).fillna(0)
                    
                    df_train_sample['dataset'] = 'Treino'
                    df_test_sample['dataset'] = 'Teste'
                    
                    full_sample = pd.concat([df_train_sample, df_test_sample])
                    X_sample = StandardScaler().fit_transform(full_sample[top_features])
                    
                    # A) PCA
                    pca = PCA(n_components=2)
                    pca_result = pca.fit_transform(X_sample)
                    full_sample['pca_1'] = pca_result[:, 0]
                    full_sample['pca_2'] = pca_result[:, 1]
                    
                    # B) t-SNE
                    logger.log("Executando t-SNE (pode demorar)...", "info")
                    tsne = TSNE(n_components=2, perplexity=50, n_iter=1000, random_state=42, 
                               init='pca', learning_rate='auto', n_jobs=-1)
                    tsne_result = tsne.fit_transform(X_sample)
                    full_sample['tsne_1'] = tsne_result[:, 0]
                    full_sample['tsne_2'] = tsne_result[:, 1]
                    
                    # 4. PLOTAGEM GERAL (LAYOUT 2x2)
                    fig, axes = plt.subplots(2, 2, figsize=(20, 16))
                    
                    # PLOT 1: Histograma KS
                    axes[0, 0].hist(drift_df['ks_statistic'], bins=15, edgecolor='black', color='steelblue', alpha=0.7)
                    axes[0, 0].axvline(0.1, color='orange', linestyle='--', linewidth=2, label='Moderado (0.1)')
                    axes[0, 0].axvline(0.2, color='red', linestyle='--', linewidth=2, label='Cr√≠tico (0.2)')
                    axes[0, 0].set_title('Distribui√ß√£o de Drift (KS Statistic)', fontsize=14, fontweight='bold')
                    axes[0, 0].set_xlabel('KS Statistic')
                    axes[0, 0].set_ylabel('Frequ√™ncia')
                    axes[0, 0].legend()
                    axes[0, 0].grid(True, alpha=0.3)
                    
                    # PLOT 2: Feature Mais Inst√°vel
                    worst_feat = drift_df.iloc[0]['feature']
                    worst_ks = drift_df.iloc[0]['ks_statistic']
                    
                    train_vals_clean = train_df[worst_feat].dropna()
                    test_vals_clean = test_df[worst_feat].dropna()
                    
                    sns.kdeplot(train_vals_clean, ax=axes[0, 1], fill=True, color='blue', 
                               label='Treino', alpha=0.2, linewidth=2)
                    sns.kdeplot(test_vals_clean, ax=axes[0, 1], fill=True, color='red', 
                               label='Teste', alpha=0.2, linewidth=2)
                    axes[0, 1].set_title(f'Pior Drift: {worst_feat} (KS={worst_ks:.4f})', 
                                        fontsize=14, fontweight='bold')
                    axes[0, 1].set_xlabel(worst_feat)
                    axes[0, 1].set_ylabel('Densidade')
                    axes[0, 1].legend()
                    axes[0, 1].grid(True, alpha=0.3)
                    
                    # Fun√ß√£o Auxiliar para Plotar Scatter + Contornos
                    def plot_contour_scatter(ax, x_col, y_col, title):
                        # Scatter de fundo
                        sns.scatterplot(
                            data=full_sample, x=x_col, y=y_col, hue='dataset', 
                            ax=ax, palette={'Treino': 'blue', 'Teste': 'red'},
                            alpha=0.15, s=15, linewidth=0, legend=False
                        )
                        
                        # Contornos de Densidade
                        sns.kdeplot(
                            data=full_sample[full_sample['dataset']=='Treino'], x=x_col, y=y_col,
                            ax=ax, color='blue', levels=5, thresh=0.1, linewidths=1.5, alpha=0.8
                        )
                        sns.kdeplot(
                            data=full_sample[full_sample['dataset']=='Teste'], x=x_col, y=y_col,
                            ax=ax, color='red', levels=5, thresh=0.1, linewidths=1.5, alpha=0.8
                        )
                        
                        ax.set_title(title, fontsize=14, fontweight='bold')
                        custom_lines = [Line2D([0], [0], color='blue', lw=2),
                                       Line2D([0], [0], color='red', lw=2)]
                        ax.legend(custom_lines, ['Treino (Contorno)', 'Teste (Contorno)'], loc='upper right')
                        ax.grid(True, alpha=0.3)
                    
                    # PLOT 3: PCA com Contornos
                    plot_contour_scatter(axes[1, 0], 'pca_1', 'pca_2', 
                                       'PCA: Estrutura Global (Com Zonas de Densidade)')
                    
                    # PLOT 4: t-SNE com Contornos
                    plot_contour_scatter(axes[1, 1], 'tsne_1', 'tsne_2', 
                                       't-SNE: Agrupamentos Locais (Com Zonas de Densidade)')
                    
                    plt.tight_layout()
                    
                    # Contexto t√©cnico para an√°lise IA
                    drift_plot_context = (
                        f"An√°lise completa de drift temporal usando KS Test, PCA e t-SNE. "
                        f"Top esquerdo: Distribui√ß√£o de KS Statistics das {len(drift_df)} features analisadas. "
                        f"Top direito: Distribui√ß√£o da feature com maior drift ({worst_feat}, KS={worst_ks:.4f}). "
                        f"Bottom esquerdo: PCA 2D mostrando estrutura global. "
                        f"Bottom direito: t-SNE 2D mostrando agrupamentos locais. "
                        f"Contornos azuis: densidade do treino. Contornos vermelhos: densidade do teste. "
                        f"Se os contornos vermelhos formarem 'ilhas' onde n√£o h√° contornos azuis, "
                        f"indica regi√µes n√£o exploradas pelo treino (risco de falha do modelo)."
                    )
                    
                    logger.log_plot(
                        fig,
                        title="An√°lise de Drift Temporal Completa",
                        description="An√°lise de drift usando KS Test, PCA e t-SNE",
                        context_description=drift_plot_context,
                        save_image=True,
                        analyze=True
                    )
                    
                    # Conclus√£o Autom√°tica
                    high_drift_count = (drift_df['ks_statistic'] > 0.15).sum()
                    if high_drift_count > 0:
                        logger.log(
                            f"CONCLUS√ÉO: {high_drift_count} features com drift alto (KS > 0.15). "
                            "Observe as linhas de contorno no t-SNE: se as linhas vermelhas formam 'ilhas' "
                            "onde n√£o h√° linhas azuis, o modelo falhar√° nessas regi√µes.",
                            "warning"
                        )
                        logger.log_insight(
                            f"{high_drift_count} features apresentam drift significativo (KS > 0.15). "
                            "Isso indica que a distribui√ß√£o dos dados de teste difere substancialmente do treino. "
                            "Recomenda-se: (1) Retreinar modelo com dados mais recentes, "
                            "(2) Aplicar t√©cnicas de domain adaptation, ou (3) Usar sample weights baseados em valida√ß√£o advers√°ria.",
                            "drift"
                        )
                    else:
                        logger.log(
                            "CONCLUS√ÉO: Estabilidade confirmada. As curvas de n√≠vel (contornos) do Treino e Teste "
                            "devem estar sobrepostas, indicando que ocupam o mesmo espa√ßo multidimensional.",
                            "success"
                        )
                        logger.log_insight(
                            "A an√°lise de drift mostra estabilidade entre treino e teste. "
                            "As distribui√ß√µes est√£o alinhadas, indicando que o modelo deve generalizar bem.",
                            "drift"
                        )
                    
                    # M√©tricas de drift
                    logger.log_metric("Features com Drift Alto (KS > 0.15)", high_drift_count)
                    logger.log_metric("Features com Drift Moderado (0.1 < KS <= 0.15)", 
                                    ((drift_df['ks_statistic'] > 0.1) & (drift_df['ks_statistic'] <= 0.15)).sum())
                    logger.log_metric("Features Est√°veis (KS <= 0.1)", 
                                    (drift_df['ks_statistic'] <= 0.1).sum())
                    logger.log_metric("KS M√©dio", f"{drift_df['ks_statistic'].mean():.4f}")
                    logger.log_metric("KS M√°ximo", f"{drift_df['ks_statistic'].max():.4f}")
                    
                    # ‚úÖ NOVO: Se√ß√£o Expl√≠cita de Sugest√£o de Blacklist para o Agente
                    toxic_features = drift_df[drift_df['ks_statistic'] > 0.5]['feature'].tolist()
                    if toxic_features:
                        logger.section("3.1.1. Sugest√£o de A√ß√£o: Remover Features com Drift Cr√≠tico", level=4)
                        logger.log(
                            f"üö® ATEN√á√ÉO AGENTE: {len(toxic_features)} features t√™m Drift Cr√≠tico (KS > 0.5). "
                            "Elas est√£o distorcendo a realidade entre Treino e Teste e devem ser removidas imediatamente.",
                            "critical"
                        )
                        logger.log_code_block(
                            json.dumps({"force_drop_features": toxic_features}, indent=2),
                            "json"
                        )
                        toxic_features_str = ', '.join([f"'{f}'" for f in toxic_features[:10]])
                        if len(toxic_features) > 10:
                            toxic_features_str += '...'
                        logger.log_insight(
                            f"**A√á√ÉO RECOMENDADA:** Adicione as seguintes features na lista 'force_drop_features' do config.yaml: "
                            f"{toxic_features_str}. "
                            "Essas features t√™m KS > 0.5, indicando que a distribui√ß√£o mudou drasticamente entre treino e teste. "
                            "Manter essas features pode causar falhas graves do modelo em produ√ß√£o.",
                            "drift_action"
                        )
                        # ‚úÖ INJE√á√ÉO DE CONTEXTO: Features t√≥xicas para o agente
                        logger.update_context("toxic_features_drift", toxic_features)
                        logger.update_context("toxic_features_count", len(toxic_features))
                
            except Exception as e:
                logger.log(f"Erro na an√°lise de drift: {e}", "error")
                import traceback
                logger.log_code_block(traceback.format_exc(), "python")
        else:
            logger.log("Bibliotecas necess√°rias n√£o dispon√≠veis para an√°lise de drift completa.", "warning")
            logger.log("Instale com: pip install scipy scikit-learn", "info")
            logger.log("An√°lise b√°sica de drift ser√° feita apenas com PSI na se√ß√£o 12.", "info")
        
        # =============================================================================
        # 4. FEATURE SELECTION
        # =============================================================================
        
        logger.section("4. Feature Selection (Conservadora)", level=2)
        
        def smart_feature_selection(df, target_col, mode='DEV'):
            """
            Sele√ß√£o de features conservadora.
            
            Mudan√ßas em rela√ß√£o √† vers√£o anterior:
            1. N√£o remove correla√ß√£o agressivamente (XGBoost lida bem com multicolinearidade).
            2. Em DEV, n√£o remove features por baixa import√¢ncia (evita corte prematuro).
            3. Sempre remove features com vari√¢ncia zero (constantes).
            
            Args:
                df: DataFrame com features e target
                target_col: Nome da coluna target
                mode: 'DEV' ou 'PROD'
            
            Returns:
                df_result: DataFrame filtrado
                kept_features: Lista de features mantidas
                dropped_vars: Lista de features removidas (apenas vari√¢ncia zero)
            """
            initial_cols = df.shape[1]
            dropped_vars = []
            
            # 1. Vari√¢ncia Zero (Sempre remover - features constantes n√£o agregam informa√ß√£o)
            try:
                from sklearn.feature_selection import VarianceThreshold
                
                # Separar colunas num√©ricas e meta-colunas
                num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
                meta_cols = [c for c in df.columns if c not in num_cols or c == target_col]
                
                if len(num_cols) > 0:
                    selector = VarianceThreshold(threshold=0.0)
                    selector.fit(df[num_cols])
                    
                    # Identificar features mantidas
                    kept_num_cols = df[num_cols].columns[selector.get_support()].tolist()
                    dropped_vars = list(set(num_cols) - set(kept_num_cols))
                    
                    if dropped_vars:
                        logger.log(f"Removidas {len(dropped_vars)} features constantes (Vari√¢ncia 0): {dropped_vars[:5]}{'...' if len(dropped_vars) > 5 else ''}", "info")
                        # Remover apenas as constantes, manter o resto
                        df = pd.concat([df[kept_num_cols], df[meta_cols]], axis=1)
            except Exception as e:
                logger.log(f"Erro no VarianceThreshold: {e}", "warning")
            
            # 2. Em DEV: N√£o aplicar filtro de correla√ß√£o nem import√¢ncia
            # XGBoost lida bem com multicolinearidade (apenas divide import√¢ncia entre vari√°veis)
            # Remover correla√ß√£o agressivamente pode jogar fora varia√ß√£o sutil √∫til
            if mode == 'DEV':
                logger.log("Modo DEV: Mantendo todas as features (exceto constantes) para visibilidade completa do Agente.", "info")
                logger.log_insight(
                    "Em modo DEV, n√£o aplicamos filtros de correla√ß√£o ou import√¢ncia para evitar corte prematuro. "
                    "O XGBoost lida bem com multicolinearidade atrav√©s de divis√£o de import√¢ncia entre vari√°veis. "
                    "Features removidas apenas por vari√¢ncia zero (constantes).",
                    "feature_selection"
                )
            
            # Features mantidas (todas exceto target e meta-colunas)
            kept_features = [c for c in df.columns if c != target_col and c not in ['split', 'dataset_origin']]
            
            logger.log_metric("Features Iniciais", initial_cols)
            logger.log_metric("Features Removidas (Vari√¢ncia Zero)", len(dropped_vars))
            logger.log_metric("Features Mantidas", len(kept_features))
            
            return df, kept_features, dropped_vars
        
        train_df = X_train.copy()
        train_df['label'] = y_train
        
        # ‚úÖ NOVO: Remover features for√ßadas pelo Agente (ex: alto drift detectado)
        force_drop_features = feature_config.get('force_drop_features', [])
        if force_drop_features:
            logger.log(f"[FEATURE DROP] Removendo {len(force_drop_features)} features banidas pelo Agente...", "warning")
            # Garantir que as colunas existam antes de dropar
            existing_drops = [c for c in force_drop_features if c in train_df.columns]
            if existing_drops:
                train_df = train_df.drop(columns=existing_drops, errors='ignore')
                logger.log(f"[FEATURE DROP] Features removidas: {', '.join(existing_drops[:10])}{'...' if len(existing_drops) > 10 else ''}", "info")
                logger.log_code_block(str(existing_drops), "json")
                # Atualizar feature_cols tamb√©m
                feature_cols = [c for c in feature_cols if c not in existing_drops]
            else:
                logger.log(f"[FEATURE DROP] Nenhuma das features solicitadas existe no dataset.", "warning")
        
        # ‚úÖ NOVA L√ìGICA: Sele√ß√£o conservadora (sem filtro de correla√ß√£o agressivo)
        df_result, kept_features, dropped_vars = smart_feature_selection(
            train_df, 'label', mode=MODO
        )
        
        feature_cols_selected = kept_features
        X_train_processed = df_result[kept_features].copy()
        
        # ‚úÖ IMPORTANTE: Processar Holdout (X_val) com a mesma sele√ß√£o de features
        # O holdout deve ser usado apenas para avalia√ß√£o final, n√£o durante o treino
        X_val_processed = None
        y_val_holdout = None
        
        if 'X_val' in locals() and X_val is not None and len(X_val) > 0:
            logger.log("Processando Holdout (X_val) com a mesma sele√ß√£o de features...", "info")
            
            # Remover features for√ßadas pelo agente
            if force_drop_features:
                X_val = X_val.drop(columns=force_drop_features, errors='ignore')
            
            # Remover features com vari√¢ncia zero
            if dropped_vars:
                X_val = X_val.drop(columns=dropped_vars, errors='ignore')
            
            # Manter apenas features selecionadas
            X_val_processed = X_val[kept_features].copy()
            y_val_holdout = y_val.copy()  # Renomear para n√£o confundir com y_val_final do treino
            
            logger.log_metric("Holdout Processado", f"{X_val_processed.shape[0]:,} amostras √ó {X_val_processed.shape[1]} features")
            logger.log_insight(
                f"Holdout separado e processado: {len(X_val_processed):,} amostras ser√£o usadas apenas para avalia√ß√£o final "
                f"(calibra√ß√£o e m√©tricas financeiras). Este conjunto n√£o foi usado durante o treino.",
                "data_split"
            )
        else:
            logger.log("Holdout (X_val) n√£o dispon√≠vel. Usando valida√ß√£o do treino para m√©tricas finais.", "warning")
        
        # ‚úÖ INJE√á√ÉO DE CONTEXTO GLOBAL: Feature Selection
        logger.update_context("n_features_selected", len(kept_features))
        logger.update_context("n_features_dropped_variance_zero", len(dropped_vars))
        logger.update_context("n_features_dropped_forced", len(force_drop_features) if force_drop_features else 0)
        
        if X_test_blind is not None and len(X_test_blind) > 0:
            # Aplicar mesmas remo√ß√µes no teste
            X_test_blind_processed = X_test_blind.drop(columns=force_drop_features + dropped_vars, errors='ignore')[kept_features].copy()
        else:
            X_test_blind_processed = None
        
        logger.log_metric("Features Mantidas", len(kept_features))
        logger.log_metric("Features Removidas (Vari√¢ncia Zero)", len(dropped_vars))
        logger.log_metric("Features Removidas (For√ßadas pelo Agente)", len(force_drop_features) if force_drop_features else 0)
        logger.log_metric("Shape Final Treino", f"{X_train_processed.shape}")
        
        # ‚úÖ MELHORIA: Mostrar amostra dos dados processados
        if hasattr(logger, 'log_dataframe_head'):
            logger.log_dataframe_head(X_train_processed.head(3), n=3, title="Amostra dos Dados Ap√≥s Feature Selection")
        else:
            # Fallback: logar apenas estat√≠sticas b√°sicas
            logger.log(f"Amostra dos dados ap√≥s feature selection: {X_train_processed.shape[0]} linhas √ó {X_train_processed.shape[1]} features", "info")
        
        # =============================================================================
        # 5. CONFIGURA√á√ÉO DO MODELO
        # =============================================================================
        
        logger.section("5. Configura√ß√£o do Modelo XGBoost", level=2)
        
        # ‚úÖ Calcular scale_pos_weight (ou usar do config se n√£o for "auto")
        scale_pos_weight_config = xgboost_config.get('scale_pos_weight', 'auto')
        if scale_pos_weight_config == 'auto':
            pos_weight = (y_train == 0).sum() / (y_train == 1).sum() if (y_train == 1).sum() > 0 else 1.0
        else:
            pos_weight = float(scale_pos_weight_config)
        
        # ‚úÖ Ler TODOS os par√¢metros do config.yaml (com fallback para valores padr√£o)
        base_params = {
            'objective': xgboost_config.get('objective', 'binary:logistic'),
            'eval_metric': xgboost_config.get('eval_metric', 'auc'),
            'tree_method': 'hist',  # Ser√° sobrescrito se GPU dispon√≠vel
            'max_depth': xgboost_config.get('max_depth', 6),
            'learning_rate': xgboost_config.get('learning_rate', 0.05),
            'subsample': xgboost_config.get('subsample', 0.8),
            'colsample_bytree': xgboost_config.get('colsample_bytree', 0.8),
            'min_child_weight': xgboost_config.get('min_child_weight', 3),
            'gamma': xgboost_config.get('gamma', 0.1),
            'scale_pos_weight': pos_weight,
            'random_state': 42,
            'n_jobs': -1,
            'verbosity': 0
        }
        
        if GPU_AVAILABLE:
            base_params['tree_method'] = 'gpu_hist'
            base_params['device'] = 'cuda'
            logger.log("Usando acelera√ß√£o GPU", "success")
        else:
            logger.log("GPU n√£o dispon√≠vel - usando CPU", "warning")
        
        logger.log_parameters(base_params, "Par√¢metros do Modelo")
        logger.log_metric("scale_pos_weight (Balanceamento)", f"{pos_weight:.3f}")
        
        # =============================================================================
        # 6. VALIDA√á√ÉO CRUZADA TEMPORAL
        # =============================================================================
        
        logger.section("6. Valida√ß√£o Cruzada Temporal", level=2)
        
        n_splits_cv = 3 if MODO == 'DEV' else 5
        print_progress("Validacao Cruzada", 0, n_splits_cv)
        
        try:
            cv_results = temporal_cross_validation(
                X_train_processed,
                y_train,
                model_params=base_params,
                n_splits=n_splits_cv,
                gap=0,
                verbose=False
            )
            print_progress("Validacao Cruzada", n_splits_cv, n_splits_cv)
            print()  # Nova linha
            
            logger.log_metric("AUC M√©dio (CV)", f"{cv_results['mean_auc']:.4f} ¬± {cv_results['std_auc']:.4f}")
            
            for i, auc in enumerate(cv_results['auc_scores'], 1):
                logger.log_metric(f"AUC Fold {i}", f"{auc:.4f}")
            
            logger.log_insight(
                f"A valida√ß√£o cruzada temporal mostra AUC m√©dio de {cv_results['mean_auc']:.4f} "
                f"com desvio padr√£o de {cv_results['std_auc']:.4f}. "
                "Esta √© a m√©trica REALISTA de treino sem vazamento temporal. "
                "Se a AUC de teste for pr√≥xima desta, o modelo est√° generalizando bem.",
                "overfitting"
            )
            
        except Exception as e:
            logger.log(f"Erro na valida√ß√£o cruzada: {e}", "error")
        
        # =============================================================================
        # 7. TREINAMENTO DO MODELO FINAL
        # =============================================================================
        
        logger.section("7. Treinamento do Modelo Final", level=2)
        
        val_size = int(len(X_train_processed) * 0.15)
        X_train_final = X_train_processed.iloc[:-val_size]
        y_train_final = y_train.iloc[:-val_size]
        X_val_final = X_train_processed.iloc[-val_size:]
        y_val_final = y_train.iloc[-val_size:]
        
        logger.log_metric("Treino Final", f"{len(X_train_final):,} amostras")
        logger.log_metric("Valida√ß√£o Final", f"{len(X_val_final):,} amostras")
        
        # ‚úÖ Configura√ß√£o baseada em modo (lendo do config.yaml)
        if MODO == 'DEV':
            n_estimators = xgboost_config.get('n_estimators_dev', 50)
            early_stopping_rounds = 10
            logger.log(f"Modo DEV: n_estimators={n_estimators} (configuracao rapida)", "info")
        else:
            n_estimators = xgboost_config.get('n_estimators_prod', 500)
            early_stopping_rounds = 30
            logger.log(f"Modo PROD: n_estimators={n_estimators} (configuracao completa)", "info")
        
        model = xgb.XGBClassifier(
            **base_params,
            n_estimators=n_estimators,
            early_stopping_rounds=early_stopping_rounds
        )
        
        logger.log("Treinando modelo...", "info")
        print_progress("Treinamento", 0, n_estimators)
        model.fit(
            X_train_final, y_train_final,
            eval_set=[(X_train_final, y_train_final), (X_val_final, y_val_final)],
            verbose=False
        )
        print_progress("Treinamento", n_estimators, n_estimators)
        print()  # Nova linha ap√≥s progress bar
        
        # Predi√ß√µes
        y_train_pred_proba = model.predict_proba(X_train_final)[:, 1]
        y_val_pred_proba = model.predict_proba(X_val_final)[:, 1]
        
        train_auc = roc_auc_score(y_train_final, y_train_pred_proba)
        val_auc = roc_auc_score(y_val_final, y_val_pred_proba)
        
        logger.log_metric("AUC Treino", f"{train_auc:.4f}")
        logger.log_metric("AUC Valida√ß√£o", f"{val_auc:.4f}")
        logger.log_metric("Gap (Overfitting)", f"{(train_auc - val_auc)*100:.2f}%")
        
        gap = train_auc - val_auc
        
        # ‚úÖ INJE√á√ÉO DE CONTEXTO GLOBAL: Performance do Modelo
        logger.update_context("auc_train", train_auc)
        logger.update_context("auc_val", val_auc)
        logger.update_context("overfitting_gap", gap)
        logger.update_context("overfitting_status", "Critical" if gap > 0.12 else "Moderate" if gap > 0.08 else "Acceptable")
        if gap > 0.12:
            logger.log("OVERFITTING CR√çTICO detectado! Gap > 12 pontos percentuais.", "error")
            logger.log_insight(
                f"O modelo est√° com overfitting severo (gap de {gap*100:.1f}%). "
                "Ser√° necess√°rio aplicar regulariza√ß√£o agressiva ou usar o protocolo de emerg√™ncia.",
                "overfitting"
            )
        elif gap > 0.08:
            logger.log("Overfitting moderado detectado. Monitorar.", "warning")
        else:
            logger.log("Modelo generalizando bem. Gap aceit√°vel.", "success")
        
        # Curva ROC
        fpr_train, tpr_train, _ = roc_curve(y_train_final, y_train_pred_proba)
        fpr_val, tpr_val, _ = roc_curve(y_val_final, y_val_pred_proba)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        ax.plot(fpr_train, tpr_train, label=f'Treino (AUC = {train_auc:.4f})', linewidth=2)
        ax.plot(fpr_val, tpr_val, label=f'Valida√ß√£o (AUC = {val_auc:.4f})', linewidth=2)
        ax.plot([0, 1], [0, 1], 'k--', label='Aleat√≥rio')
        ax.set_xlabel('Taxa de Falsos Positivos')
        ax.set_ylabel('Taxa de Verdadeiros Positivos')
        ax.set_title('Curva ROC - Treino vs Valida√ß√£o')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ‚úÖ MELHORIA: Descri√ß√£o textual da geometria da curva ROC
        # ‚úÖ Usando geometria robusta para evitar falsos zeros
        roc_geometry_desc = describe_curve_geometry_robust(fpr_val, tpr_val, "Curva ROC (Valida√ß√£o)")
        roc_description = logger.describe_roc_curve(fpr_val, tpr_val, val_auc)
        
        # ‚úÖ Contexto t√©cnico detalhado com refer√™ncia ao contexto global
        balance_info = logger.global_context.get("target_imbalance_status", "Unknown")
        balance_ratio = logger.global_context.get("class_balance_ratio", "N/A")
        
        roc_plot_context = (
            f"Curva ROC do modelo XGBoost (Valida√ß√£o). "
            f"AUC: {val_auc:.4f}. Gap Treino-Val: {gap:.4f} ({'Cr√≠tico' if gap > 0.12 else 'Moderado' if gap > 0.08 else 'Aceit√°vel'}). "
            f"O contexto global indica desbalanceamento: {balance_info} (raz√£o: {balance_ratio}), "
            f"o que torna a curva ROC sens√≠vel. "
            f"{roc_description}\n\n"
            f"{roc_geometry_desc}"
        )
        
        logger.log_plot(
            fig,
            title="Curva ROC - Treino vs Valida√ß√£o",
            description=f"Curva ROC comparando treino (AUC={train_auc:.4f}) e valida√ß√£o (AUC={val_auc:.4f})",
            context_description=roc_plot_context,
            save_image=True,
            analyze=True
        )
        
        # =============================================================================
        # 8. PROTOCOLO DE EMERG√äNCIA (se necess√°rio)
        # =============================================================================
        
        if gap > 0.08:
            logger.section("8. Protocolo de Emerg√™ncia: Regulariza√ß√£o Agressiva", level=2)
            
            params_anti_overfit = {
                'objective': 'binary:logistic',
                'eval_metric': 'auc',
                'max_depth': 3,
                'min_child_weight': 50,
                'gamma': 5.0,
                'subsample': 0.6,
                'colsample_bytree': 0.5,
                'reg_alpha': 10.0,
                'reg_lambda': 10.0,
                'learning_rate': 0.05,
                'n_jobs': -1,
                'random_state': 42,
                'verbosity': 0
            }
            
            if GPU_AVAILABLE:
                params_anti_overfit['tree_method'] = 'gpu_hist'
                params_anti_overfit['device'] = 'cuda'
            
            if MODO == 'DEV':
                n_estimators_robust = 50
                early_stopping_robust = 10
            else:
                n_estimators_robust = 1000
                early_stopping_robust = 50
            
            model_robust = xgb.XGBClassifier(
                **params_anti_overfit,
                n_estimators=n_estimators_robust,
                early_stopping_rounds=early_stopping_robust
            )
            
            logger.log("Retreinando com restri√ß√µes severas...", "info")
            model_robust.fit(
                X_train_final, y_train_final,
                eval_set=[(X_train_final, y_train_final), (X_val_final, y_val_final)],
                verbose=False
            )
            
            y_train_prob_robust = model_robust.predict_proba(X_train_final)[:, 1]
            y_val_prob_robust = model_robust.predict_proba(X_val_final)[:, 1]
            
            new_auc_train = roc_auc_score(y_train_final, y_train_prob_robust)
            new_auc_val = roc_auc_score(y_val_final, y_val_prob_robust)
            
            new_gap = new_auc_train - new_auc_val
            
            logger.log_metric("AUC Treino (Robusto)", f"{new_auc_train:.4f}")
            logger.log_metric("AUC Valida√ß√£o (Robusto)", f"{new_auc_val:.4f}")
            logger.log_metric("Gap (Robusto)", f"{new_gap*100:.2f}%")
            
            if new_gap < 0.08:
                logger.log("Sucesso: O Gap foi fechado. O modelo agora √© honesto.", "success")
                model = model_robust
                train_auc = new_auc_train
                val_auc = new_auc_val
            else:
                logger.log("Aten√ß√£o: O Gap diminuiu mas persiste.", "warning")
                model = model_robust
                train_auc = new_auc_train
                val_auc = new_auc_val
        
        # =============================================================================
        # 9. SHAP VALUES (Explainability)
        # =============================================================================
        
        # ‚úÖ OTIMIZA√á√ÉO: Pular SHAP no modo DEV ou se run_shap=False
        if SHAP_AVAILABLE and RUN_SHAP and MODO != 'DEV':
            logger.section("9. SHAP Values - Explainability", level=2)
            
            # Amostra reduzida para acelerar (1000 amostras)
            X_shap_sample = X_train_final.sample(n=min(1000, len(X_train_final)), random_state=42)
            
            logger.log("Calculando valores SHAP (pode demorar)...", "info")
            print_progress("SHAP", 0, len(X_shap_sample))
            
            explainer = shap.TreeExplainer(model)
            shap_explanation = explainer(X_shap_sample)
            
            print_progress("SHAP", len(X_shap_sample), len(X_shap_sample))
            print()  # Nova linha ap√≥s progress bar
            
            # ‚úÖ CORRE√á√ÉO: Calcular shap_summary ANTES de usar no contexto
            shap_summary = pd.Series(
                np.abs(shap_explanation.values).mean(0),
                index=X_shap_sample.columns
            ).sort_values(ascending=False)
            
            # Gr√°fico beeswarm
            fig = plt.figure(figsize=(12, 8))
            shap.plots.beeswarm(shap_explanation, max_display=20, show=False)
            plt.title('Impacto das Features na Decis√£o (SHAP)', fontsize=14)
            plt.tight_layout()
            
            # Contexto t√©cnico detalhado para an√°lise IA do SHAP
            shap_plot_context = (
                f"Gr√°fico beeswarm SHAP mostrando o impacto das top 20 features nas decis√µes do modelo XGBoost. "
                f"Features ordenadas por import√¢ncia m√©dia (SHAP value absoluto). "
                f"Pontos vermelhos: valores altos da feature. Pontos azuis: valores baixos. "
                f"Eixo X positivo: aumenta risco de cr√©dito (default). Eixo X negativo: diminui risco. "
                f"Feature mais importante: {shap_summary.index[0]} (impacto m√©dio: {shap_summary.iloc[0]:.4f}). "
                f"Se uma feature separar perfeitamente as classes (cores n√£o se misturam), pode indicar data leakage."
            )
            
            logger.log_plot(
                fig,
                title="SHAP Values - Impacto das Features",
                description="Gr√°fico beeswarm SHAP mostrando impacto das top 20 features",
                context_description=shap_plot_context,
                save_image=True,
                analyze=True
            )
            
            logger.log_table("Top 10 Features por Import√¢ncia SHAP",
                            {k: f"{v:.4f}" for k, v in shap_summary.head(10).items()})
            
            logger.log_insight(
                f"A feature mais importante segundo SHAP √© {shap_summary.index[0]} "
                f"com impacto m√©dio de {shap_summary.iloc[0]:.4f}. "
                "Se esta feature separar perfeitamente as classes, pode indicar data leakage.",
                "explainability"
            )
        elif SHAP_AVAILABLE and (not RUN_SHAP or MODO == 'DEV'):
            # Modo DEV ou SHAP desabilitado: pular completamente
            logger.section("9. SHAP Values - Explainability", level=2)
            if MODO == 'DEV':
                logger.log("SHAP pulado no modo DEV para acelerar desenvolvimento. Execute em modo PROD para an√°lise completa.", "info")
            else:
                logger.log("SHAP desabilitado no config.yaml (run_shap: false).", "info")
            logger.log_insight(
                "An√°lise SHAP n√£o foi executada. Para ativar, configure 'run_shap: true' no config.yaml e execute em modo PROD.",
                "explainability"
            )
        elif not SHAP_AVAILABLE:
            logger.section("9. SHAP Values - Explainability", level=2)
            logger.log("SHAP n√£o dispon√≠vel. Instale com: pip install shap", "warning")
        
        # =============================================================================
        # 10. CALIBRA√á√ÉO DE PROBABILIDADES
        # =============================================================================
        
        logger.section("10. Calibra√ß√£o de Probabilidades", level=2)
        
        try:
            from sklearn.calibration import CalibratedClassifierCV
            from sklearn.metrics import brier_score_loss
            
            logger.log_timestamp("In√≠cio da calibra√ß√£o")
            
            # ‚úÖ CORRE√á√ÉO CR√çTICA: Criar modelo limpo sem early_stopping_rounds
            # O CalibratedClassifierCV faz cross-validation interno e n√£o passa eval_set
            calib_base = xgb.XGBClassifier(
                **{k: v for k, v in base_params.items() if k not in ['n_estimators', 'early_stopping_rounds']},
                n_estimators=300  # Fixo, sem early stopping
            )
            
            model_calibrated = CalibratedClassifierCV(
                calib_base, method='isotonic', cv=3
            )
            
            logger.log("Calibrando probabilidades (m√©todo isot√¥nico, cv=3)...", "info")
            model_calibrated.fit(X_train_final, y_train_final)
            
            # ‚úÖ MUDAN√áA: Usar Holdout (X_val_processed) para avalia√ß√£o final, se dispon√≠vel
            # Se n√£o houver holdout, usar valida√ß√£o do treino como fallback
            if X_val_processed is not None and y_val_holdout is not None:
                eval_X = X_val_processed
                eval_y = y_val_holdout
                logger.log(f"Usando Holdout para avalia√ß√£o final: {len(eval_X):,} amostras", "info")
            else:
                eval_X = X_val_final
                eval_y = y_val_final
                logger.log(f"Holdout n√£o dispon√≠vel. Usando valida√ß√£o do treino: {len(eval_X):,} amostras", "warning")
            
            # Predi√ß√µes antes e depois da calibra√ß√£o
            prob_raw = model.predict_proba(eval_X)[:, 1]
            y_val_proba_cal = model_calibrated.predict_proba(eval_X)[:, 1]
            
            # M√©tricas de calibra√ß√£o
            loss_raw = brier_score_loss(eval_y, prob_raw)
            loss_cal = brier_score_loss(eval_y, y_val_proba_cal)
            
            logger.log_metric("Brier Score (Antes da Calibra√ß√£o)", f"{loss_raw:.4f}")
            logger.log_metric("Brier Score (Depois da Calibra√ß√£o)", f"{loss_cal:.4f}")
            logger.log_metric("Melhoria no Brier Score", f"{(loss_raw - loss_cal):.4f} ({(loss_raw - loss_cal)/loss_raw*100:.1f}%)")
            
            # ‚úÖ NOVO: Plot de Calibra√ß√£o (Probabilidade Prevista vs Observada)
            try:
                from sklearn.calibration import calibration_curve
                
                # Calcular curvas de calibra√ß√£o antes e depois (usar eval_y)
                fraction_of_positives_raw, mean_predicted_value_raw = calibration_curve(
                    eval_y, prob_raw, n_bins=10, strategy='uniform'
                )
                fraction_of_positives_cal, mean_predicted_value_cal = calibration_curve(
                    eval_y, y_val_proba_cal, n_bins=10, strategy='uniform'
                )
                
                fig, ax = plt.subplots(figsize=(10, 8))
                
                # Linha de calibra√ß√£o perfeita (diagonal)
                ax.plot([0, 1], [0, 1], 'k--', label='Calibra√ß√£o Perfeita', linewidth=2)
                
                # Curva antes da calibra√ß√£o
                ax.plot(mean_predicted_value_raw, fraction_of_positives_raw, 
                       'o-', color='red', label=f'Antes (Brier={loss_raw:.4f})', 
                       linewidth=2, markersize=8)
                
                # Curva depois da calibra√ß√£o
                ax.plot(mean_predicted_value_cal, fraction_of_positives_cal, 
                       'o-', color='green', label=f'Depois (Brier={loss_cal:.4f})', 
                       linewidth=2, markersize=8)
                
                ax.set_xlabel('Probabilidade M√©dia Prevista', fontsize=12)
                ax.set_ylabel('Fra√ß√£o de Positivos Observada', fontsize=12)
                ax.set_title('Curva de Calibra√ß√£o: Antes vs Depois', fontsize=14, fontweight='bold')
                ax.legend(loc='best', fontsize=11)
                ax.grid(True, alpha=0.3)
                plt.tight_layout()
                
                calib_context = (
                    f"Curva de calibra√ß√£o comparando probabilidades antes e depois da calibra√ß√£o isot√¥nica. "
                    f"Quanto mais pr√≥xima da diagonal (linha preta tracejada), melhor a calibra√ß√£o. "
                    f"Brier Score melhorou de {loss_raw:.4f} para {loss_cal:.4f} "
                    f"({(loss_raw - loss_cal)/loss_raw*100:.1f}% de melhoria)."
                )
                
                logger.log_plot(
                    fig,
                    title="Curva de Calibra√ß√£o - Antes vs Depois",
                    description="Compara√ß√£o de calibra√ß√£o antes e depois da aplica√ß√£o do m√©todo isot√¥nico",
                    context_description=calib_context,
                    save_image=True,
                    analyze=True
                )
            except Exception as e:
                logger.log(f"Erro ao gerar plot de calibra√ß√£o: {e}", "warning")
            
            logger.log("Calibra√ß√£o conclu√≠da", "success")
            logger.log_insight(
                f"As probabilidades foram calibradas usando m√©todo isot√¥nico. "
                f"O Brier Score melhorou de {loss_raw:.4f} para {loss_cal:.4f} "
                f"({(loss_raw - loss_cal)/loss_raw*100:.1f}% de melhoria). "
                "Isso garante que probabilidades de 0.7 realmente significam 70% de chance de default, "
                "essencial para decis√µes financeiras precisas.",
                "calibration"
            )
            
            logger.log_timestamp("Fim da calibra√ß√£o")
            
        except Exception as e:
            logger.log(f"Erro na calibra√ß√£o: {e}", "error")
            import traceback
            logger.log_code_block(traceback.format_exc(), "python")
            model_calibrated = model
            y_val_proba_cal = model.predict_proba(X_val_final)[:, 1]
        
        # =============================================================================
        # 11. AN√ÅLISE FINANCEIRA
        # =============================================================================
        
        logger.section("11. An√°lise de Impacto Financeiro", level=2)
        
        # ‚úÖ Ler par√¢metros financeiros do config.yaml
        cost_matrix = business_config.get('cost_matrix', {})
        TICKET_MEDIO = business_config.get('ticket_medio', 10000)
        GANHO_TP = cost_matrix.get('tp', business_config.get('ganho_tp', 1500))
        PERDA_FN = cost_matrix.get('fn', 0)
        PERDA_FP = cost_matrix.get('fp', business_config.get('perda_fp', -10000))
        GANHO_TN = cost_matrix.get('tn', 0)
        
        # ‚úÖ Formata√ß√£o sem R$ para evitar conflito com LaTeX no Markdown
        logger.log_metric("Ticket M√©dio", f"{TICKET_MEDIO:,.2f}")
        logger.log_metric("Ganho TP", f"{GANHO_TP:,.2f}")
        logger.log_metric("Perda FP", f"{PERDA_FP:,.2f}")
        
        logger.log_parameters({
            'TICKET_MEDIO': TICKET_MEDIO,
            'GANHO_TP': GANHO_TP,
            'PERDA_FP': PERDA_FP,
            'PERDA_FN': PERDA_FN,
            'GANHO_TN': GANHO_TN
        }, "Par√¢metros Financeiros")
        
        try:
            cost_matrix_dict = {
                'tp': GANHO_TP,
                'fp': PERDA_FP,
                'fn': PERDA_FN,
                'tn': GANHO_TN
            }
            
            # ‚úÖ MUDAN√áA: Usar Holdout (eval_y_financial) para otimiza√ß√£o financeira, se dispon√≠vel
            if X_val_processed is not None and y_val_holdout is not None and 'model_calibrated' in locals():
                eval_y_financial = y_val_holdout
                # Recalcular probabilidades no holdout usando modelo calibrado
                eval_y_proba_cal = model_calibrated.predict_proba(X_val_processed)[:, 1]
                y_proba_for_threshold = eval_y_proba_cal
                logger.log(f"Otimiza√ß√£o financeira usando Holdout: {len(eval_y_financial):,} amostras", "info")
            else:
                # Fallback: usar valida√ß√£o do treino
                eval_y_financial = y_val_final
                y_proba_for_threshold = y_val_proba_cal if 'y_val_proba_cal' in locals() else y_val_pred_proba
                logger.log(f"Otimiza√ß√£o financeira usando valida√ß√£o do treino: {len(eval_y_financial):,} amostras", "warning")
            
            # ‚úÖ VALIDA√á√ÉO CR√çTICA: Garantir que tamanhos s√£o consistentes
            if len(eval_y_financial) != len(y_proba_for_threshold):
                logger.log(
                    f"ERRO CR√çTICO: Tamanhos inconsistentes! eval_y_financial={len(eval_y_financial)}, "
                    f"y_proba_for_threshold={len(y_proba_for_threshold)}. Corrigindo...",
                    "error"
                )
                # Usar o menor tamanho comum
                min_len = min(len(eval_y_financial), len(y_proba_for_threshold))
                eval_y_financial = eval_y_financial[:min_len].copy()
                y_proba_for_threshold = y_proba_for_threshold[:min_len].copy()
                logger.log(f"Tamanhos ajustados para {min_len} amostras", "warning")
            
            # ‚úÖ VALIDA√á√ÉO FINAL: Verificar novamente antes de chamar fun√ß√£o
            if len(eval_y_financial) != len(y_proba_for_threshold):
                raise ValueError(
                    f"Falha ao corrigir tamanhos inconsistentes: "
                    f"eval_y_financial={len(eval_y_financial)}, "
                    f"y_proba_for_threshold={len(y_proba_for_threshold)}"
                )
            
            threshold_results = find_optimal_threshold(
                eval_y_financial,
                y_proba_for_threshold,
                cost_matrix=cost_matrix_dict
            )
            
            optimal_threshold = threshold_results['optimal_threshold']
            max_profit = threshold_results['optimal_profit']
            all_results = threshold_results['all_results']
            
            # ‚úÖ NOVO: Calcular Lucro Potencial M√°ximo (Teto Te√≥rico) usando eval_y_financial
            max_potential_profit = calculate_max_potential_profit(eval_y_financial, cost_matrix_dict)
            
            # ‚úÖ NOVO: Calcular Efici√™ncia Financeira (% do Potencial)
            if max_potential_profit > 0:
                financial_efficiency = (max_profit / max_potential_profit) * 100
            else:
                financial_efficiency = 0.0
            
            logger.log_metric("Threshold √ìtimo", f"{optimal_threshold:.4f}")
            # ‚úÖ Formata√ß√£o sem R$ para evitar conflito com LaTeX
            logger.log_metric("Lucro Real (Amostra)", f"{max_profit:,.2f}")
            logger.log_metric("Lucro Potencial M√°ximo (Te√≥rico)", f"{max_potential_profit:,.2f}")
            logger.log_metric("Efici√™ncia Financeira (% do Potencial)", f"{financial_efficiency:.2f}%")
            
            # ‚úÖ ENFATIZAR: Esta m√©trica √© agn√≥stica ao tamanho da amostra
            logger.log(
                f"**IMPORTANTE:** A Efici√™ncia Financeira de {financial_efficiency:.2f}% √© uma m√©trica agn√≥stica ao tamanho da amostra. "
                f"Ela funciona igual em modo DEV (10k linhas) e PROD (500k linhas). "
                f"Meta: > 75% de efici√™ncia.",
                "info"
            )
            
            # ‚úÖ INJE√á√ÉO DE CONTEXTO GLOBAL: M√©tricas Financeiras
            logger.update_context("financial_efficiency_percent", financial_efficiency)
            logger.update_context("profit_real", max_profit)
            logger.update_context("profit_potential_max", max_potential_profit)
            
            # ‚úÖ MELHORIA: Descri√ß√£o textual da curva de lucro
            thresholds_array = all_results['threshold'].values
            profits_array = all_results['profit'].values
            
            profit_curve_desc = describe_curve_geometry_robust(thresholds_array, profits_array, "Curva de Lucro")
            logger.log(profit_curve_desc, "info")
            
            # ‚úÖ NOVO: Plot Completo de Curvas de Lucro vs Threshold vs Taxa de Aprova√ß√£o
            try:
                # Calcular taxas de aprova√ß√£o para cada threshold (usar eval_y_financial para tamanho correto)
                approval_rates = []
                for t in thresholds_array:
                    approved = np.sum(y_proba_for_threshold >= t)
                    approval_rates.append(approved / len(eval_y_financial) * 100)
                approval_rates = np.array(approval_rates)
                
                fig, axes = plt.subplots(2, 1, figsize=(14, 10))
                
                # Plot 1: Lucro vs Threshold
                axes[0].plot(thresholds_array, profits_array, linewidth=2.5, color='steelblue', label='Lucro Esperado')
                axes[0].axvline(optimal_threshold, color='red', linestyle='--', linewidth=2, 
                               label=f'Threshold √ìtimo = {optimal_threshold:.3f}')
                axes[0].axhline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)
                axes[0].axhline(max_profit, color='green', linestyle=':', linewidth=1.5, alpha=0.7,
                               label=f'Lucro M√°ximo = {max_profit:,.0f}')
                
                # Zona de preju√≠zo e lucro
                axes[0].fill_between(thresholds_array, 0, profits_array, where=(profits_array < 0), 
                                   color='red', alpha=0.2, label='Zona de Preju√≠zo')
                axes[0].fill_between(thresholds_array, 0, profits_array, where=(profits_array >= 0), 
                                   color='green', alpha=0.2, label='Zona de Lucro')
                
                axes[0].set_xlabel('Threshold de Corte (Probabilidade M√≠nima para Aprovar)', fontsize=12)
                axes[0].set_ylabel('Lucro Esperado', fontsize=12)
                axes[0].set_title('üí∞ Curva de Lucro Esperado vs Threshold de Corte', 
                                fontsize=14, fontweight='bold')
                axes[0].legend(loc='best', fontsize=11)
                axes[0].grid(True, alpha=0.3)
                
                # Anota√ß√£o do ponto √≥timo
                axes[0].annotate(
                    f'√ìtimo\n{max_profit:,.0f}',
                    xy=(optimal_threshold, max_profit),
                    xytext=(optimal_threshold + 0.1, max_profit + max_profit*0.1),
                    arrowprops=dict(arrowstyle='->', color='red', lw=2),
                    fontsize=11, fontweight='bold',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7)
                )
                
                # Plot 2: Taxa de Aprova√ß√£o vs Threshold
                axes[1].plot(thresholds_array, approval_rates, linewidth=2, color='orange', 
                           label='Taxa de Aprova√ß√£o (%)', alpha=0.8)
                axes[1].axvline(optimal_threshold, color='red', linestyle='--', linewidth=2,
                               label=f'Threshold √ìtimo = {optimal_threshold:.3f}')
                
                # Calcular taxa de aprova√ß√£o no threshold √≥timo (usar eval_y_financial para tamanho correto)
                optimal_approval_rate = np.sum(y_proba_for_threshold >= optimal_threshold) / len(eval_y_financial) * 100
                axes[1].axhline(optimal_approval_rate, color='green', linestyle=':', linewidth=1.5, alpha=0.7,
                               label=f'Taxa √ìtima = {optimal_approval_rate:.1f}%')
                
                axes[1].set_xlabel('Threshold de Corte', fontsize=12)
                axes[1].set_ylabel('Taxa de Aprova√ß√£o (%)', fontsize=12)
                axes[1].set_title('Taxa de Aprova√ß√£o vs Threshold', fontsize=12, fontweight='bold')
                axes[1].legend(loc='best', fontsize=11)
                axes[1].grid(True, alpha=0.3)
                
                plt.tight_layout()
                
                profit_plot_context = (
                    f"An√°lise completa de otimiza√ß√£o financeira. "
                    f"Topo: Curva de lucro vs threshold. O threshold √≥timo ({optimal_threshold:.4f}) maximiza lucro em {max_profit:,.0f}. "
                    f"Zonas verdes indicam lucro, zonas vermelhas indicam preju√≠zo. "
                    f"Base: Taxa de aprova√ß√£o vs threshold. No threshold √≥timo, aprovamos {optimal_approval_rate:.1f}% dos casos. "
                    f"Esta visualiza√ß√£o permite balancear lucro m√°ximo com volume de neg√≥cios."
                )
                
                logger.log_plot(
                    fig,
                    title="Curvas de Lucro e Taxa de Aprova√ß√£o vs Threshold",
                    description="An√°lise completa de otimiza√ß√£o financeira: lucro esperado e taxa de aprova√ß√£o em fun√ß√£o do threshold",
                    context_description=profit_plot_context,
                    save_image=True,
                    analyze=True
                )
            except Exception as e:
                logger.log(f"Erro ao gerar plot de curvas de lucro: {e}", "warning")
            
            # Identificar zona de estabilidade (flat-top)
            profit_max = np.max(profits_array)
            profit_threshold = profit_max * 0.95  # 95% do m√°ximo
            stable_zone_indices = np.where(profits_array >= profit_threshold)[0]
            
            if len(stable_zone_indices) > 1:
                t_min = thresholds_array[stable_zone_indices[0]]
                t_max = thresholds_array[stable_zone_indices[-1]]
                profit_variation = (np.max(profits_array[stable_zone_indices]) - np.min(profits_array[stable_zone_indices])) / profit_max * 100
                
                logger.log_insight(
                    f"A zona de lucro m√°ximo √© plana (flat-top), variando menos de {profit_variation:.1f}% "
                    f"entre os thresholds {t_min:.3f} e {t_max:.3f}. "
                    "Isso indica que o modelo √© robusto a pequenas varia√ß√µes na pol√≠tica de corte nesta faixa.",
                    "financeiro"
                )
            
            # Calcular m√©tricas no threshold √≥timo usando eval_y_financial
            y_pred_optimal = (y_proba_for_threshold >= optimal_threshold).astype(int)
            cm = confusion_matrix(eval_y_financial, y_pred_optimal)
            tn, fp, fn, tp = cm.ravel()
            
            logger.log_table("Matriz de Confus√£o (Threshold √ìtimo)", {
                'True Negatives (TN)': int(tn),
                'False Positives (FP)': int(fp),
                'False Negatives (FN)': int(fn),
                'True Positives (TP)': int(tp)
            })
            
            # ‚úÖ NOVO: Plot de Matriz de Confus√£o com Custos
            try:
                fig, axes = plt.subplots(1, 2, figsize=(16, 6))
                
                # Plot 1: Matriz de Confus√£o (Contagem)
                cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],
                           xticklabels=['Negativo (0)', 'Positivo (1)'],
                           yticklabels=['Negativo (0)', 'Positivo (1)'],
                           cbar_kws={'label': 'Contagem'})
                axes[0].set_title('Matriz de Confus√£o (Contagem)', fontsize=13, fontweight='bold')
                axes[0].set_ylabel('Verdadeiro', fontsize=11)
                axes[0].set_xlabel('Previsto', fontsize=11)
                
                # Plot 2: Matriz de Custos Financeiros
                cost_matrix_vis = np.array([
                    [tn * GANHO_TN, fp * PERDA_FP],  # Linha 0: Verdadeiro Negativo
                    [fn * PERDA_FN, tp * GANHO_TP]   # Linha 1: Verdadeiro Positivo
                ])
                
                sns.heatmap(cost_matrix_vis, annot=True, fmt='.0f', cmap='RdYlGn', 
                           center=0, ax=axes[1],
                           xticklabels=['Negativo (0)', 'Positivo (1)'],
                           yticklabels=['Negativo (0)', 'Positivo (1)'],
                           cbar_kws={'label': 'Custo/Benef√≠cio (R$)'})
                axes[1].set_title('Matriz de Custos Financeiros (R$)', fontsize=13, fontweight='bold')
                axes[1].set_ylabel('Verdadeiro', fontsize=11)
                axes[1].set_xlabel('Previsto', fontsize=11)
                
                plt.tight_layout()
                
                cm_context = (
                    f"Matriz de confus√£o e custos financeiros no threshold √≥timo ({optimal_threshold:.4f}). "
                    f"Esquerda: Contagem de acertos/erros (TN={tn}, FP={fp}, FN={fn}, TP={tp}). "
                    f"Direita: Impacto financeiro por c√©lula. "
                    f"Erro Tipo I (FP): Aprovamos caloteiro = {fp} √ó {abs(PERDA_FP):,.0f} = {fp * PERDA_FP:,.0f}. "
                    f"Erro Tipo II (FN): Negamos bom pagador = {fn} √ó {abs(PERDA_FN):,.0f} = {fn * PERDA_FN:,.0f}. "
                    f"Lucro Total: {tp * GANHO_TP + fp * PERDA_FP + fn * PERDA_FN + tn * GANHO_TN:,.0f}."
                )
                
                logger.log_plot(
                    fig,
                    title="Matriz de Confus√£o e Custos Financeiros",
                    description="Compara√ß√£o entre matriz de confus√£o (contagem) e matriz de custos (impacto financeiro)",
                    context_description=cm_context,
                    save_image=True,
                    analyze=True
                )
            except Exception as e:
                logger.log(f"Erro ao gerar plot de matriz de confus√£o: {e}", "warning")
            
            logger.log_insight(
                f"O threshold √≥timo para maximizar lucro √© {optimal_threshold:.4f}, "
                f"gerando lucro esperado de {max_profit:,.2f} (amostra atual). "
                f"**M√âTRICA PRINCIPAL:** O modelo capturou **{financial_efficiency:.2f}%** de todo o dinheiro dispon√≠vel na mesa "
                f"(lucro potencial m√°ximo te√≥rico: {max_potential_profit:,.2f}). "
                f"Esta m√©trica de efici√™ncia √© AGN√ìSTICA ao tamanho da amostra (funciona igual em DEV e PROD). "
                f"Uma efici√™ncia > 75% √© considerada excelente em cr√©dito. "
                f"Com este threshold, temos {tp} aprova√ß√µes corretas (TP) e {fp} aprova√ß√µes incorretas (FP). "
                "Este threshold √© mais conservador que o padr√£o de 0.5, "
                "refletindo o risco assim√©trico do neg√≥cio onde perder 10.000 em um calote "
                "√© muito pior do que perder 1.500 em juros de um bom pagador.",
                "financeiro"
            )
            
        except Exception as e:
            logger.log(f"Erro na otimiza√ß√£o financeira: {e}", "error")
            import traceback
            logger.log_code_block(traceback.format_exc(), "python")
        
        # =============================================================================
        # 11.5. AN√ÅLISE DE ELASTICIDADE: AUC vs LUCRO
        # =============================================================================
        
        logger.section("11.5. An√°lise de Elasticidade: Sensibilidade do Lucro √† AUC", level=2)
        
        try:
            # ‚úÖ Verificar se temos todas as vari√°veis necess√°rias
            has_proba = 'y_proba_for_threshold' in locals() or 'y_val_proba_cal' in locals() or 'eval_y_proba_cal' in locals()
            has_threshold = 'optimal_threshold' in locals()
            has_eval_y = 'eval_y_financial' in locals()
            
            if has_proba and has_threshold and has_eval_y:
                logger.log("Simulando degrada√ß√£o controlada da AUC para medir elasticidade do lucro...", "info")
                
                # Usar holdout para an√°lise de elasticidade (mesmas vari√°veis da otimiza√ß√£o financeira)
                y_elasticity_true = eval_y_financial
                # Usar a mesma probabilidade que foi usada na otimiza√ß√£o financeira
                if 'y_proba_for_threshold' in locals():
                    y_elasticity_proba = y_proba_for_threshold
                elif 'eval_y_proba_cal' in locals():
                    y_elasticity_proba = eval_y_proba_cal
                elif 'y_val_proba_cal' in locals():
                    y_elasticity_proba = y_val_proba_cal
                else:
                    raise ValueError("Nenhuma probabilidade dispon√≠vel para an√°lise de elasticidade")
                
                # ‚úÖ VALIDA√á√ÉO CR√çTICA: Garantir tamanhos consistentes
                if len(y_elasticity_true) != len(y_elasticity_proba):
                    logger.log(
                        f"ERRO CR√çTICO: Tamanhos inconsistentes na elasticidade! "
                        f"y_elasticity_true={len(y_elasticity_true)}, "
                        f"y_elasticity_proba={len(y_elasticity_proba)}. Corrigindo...",
                        "error"
                    )
                    min_len = min(len(y_elasticity_true), len(y_elasticity_proba))
                    y_elasticity_true = y_elasticity_true[:min_len].copy()
                    y_elasticity_proba = y_elasticity_proba[:min_len].copy()
                    logger.log(f"Tamanhos ajustados para {min_len} amostras", "warning")
                
                # ‚úÖ VALIDA√á√ÉO FINAL antes de prosseguir
                if len(y_elasticity_true) != len(y_elasticity_proba):
                    raise ValueError(
                        f"Falha ao corrigir tamanhos na elasticidade: "
                        f"y_elasticity_true={len(y_elasticity_true)}, "
                        f"y_elasticity_proba={len(y_elasticity_proba)}"
                    )
                
                # Executar simula√ß√£o
                df_elasticity = simulate_auc_elasticity(
                    y_elasticity_true,
                    y_elasticity_proba,
                    cost_matrix_dict,
                    fixed_threshold=optimal_threshold,
                    n_steps=100,
                    random_seed=42
                )
                
                if len(df_elasticity) > 10:
                    # Calcular coeficiente de elasticidade
                    elasticity_coef, df_reg = calculate_elasticity_coefficient(df_elasticity)
                    
                    # Calcular valor marginal nos √∫ltimos 5% de AUC
                    max_auc = df_elasticity['auc'].max()
                    top_tier = df_elasticity[df_elasticity['auc'] >= max_auc * 0.95]
                    
                    if len(top_tier) > 1:
                        delta_profit = top_tier['profit'].max() - top_tier['profit'].min()
                        delta_auc = top_tier['auc'].max() - top_tier['auc'].min()
                        marginal_value_per_1pct_auc = delta_profit / (delta_auc * 100) if delta_auc > 0 else 0
                    else:
                        marginal_value_per_1pct_auc = 0
                    
                    # Plot de Elasticidade
                    fig, ax = plt.subplots(figsize=(14, 8))
                    
                    # Scatter plot dos dados simulados
                    ax.scatter(df_elasticity['auc'], df_elasticity['profit'], 
                              alpha=0.6, color='#3498db', edgecolor='white', s=60, label='Simula√ß√£o')
                    
                    # Linha de tend√™ncia (Regress√£o Polinomial para suavizar visualmente)
                    try:
                        from sklearn.preprocessing import PolynomialFeatures
                        from sklearn.pipeline import Pipeline
                        from sklearn.linear_model import LinearRegression
                        
                        poly_reg = Pipeline([
                            ('poly', PolynomialFeatures(degree=2)),
                            ('linear', LinearRegression())
                        ])
                        X_poly = df_elasticity[['auc']].values
                        y_poly = df_elasticity['profit'].values
                        poly_reg.fit(X_poly, y_poly)
                        
                        X_plot = np.linspace(df_elasticity['auc'].min(), df_elasticity['auc'].max(), 200).reshape(-1, 1)
                        y_plot = poly_reg.predict(X_plot)
                        ax.plot(X_plot, y_plot, '--', color='#e74c3c', linewidth=2.5, label='Tend√™ncia (Fit Polinomial)', alpha=0.8)
                    except:
                        # Fallback: regress√£o linear simples
                        z = np.polyfit(df_elasticity['auc'], df_elasticity['profit'], 2)
                        p = np.poly1d(z)
                        x_trend = np.linspace(df_elasticity['auc'].min(), df_elasticity['auc'].max(), 200)
                        ax.plot(x_trend, p(x_trend), '--', color='#e74c3c', linewidth=2.5, label='Tend√™ncia (Fit)', alpha=0.8)
                    
                    # Marcar ponto atual (melhor modelo)
                    current_auc = roc_auc_score(y_elasticity_true, y_elasticity_proba)
                    current_profit = max_profit
                    ax.scatter([current_auc], [current_profit], color='green', s=200, 
                             marker='*', edgecolor='black', linewidth=2, zorder=5,
                             label=f'Modelo Atual (AUC={current_auc:.3f})')
                    
                    # Anota√ß√£o de Elasticidade
                    if len(df_elasticity) > 20:
                        mid_idx = len(df_elasticity) // 3
                        ax.annotate(
                            f'Elasticidade Alta:\nPequeno ganho de AUC\n= Grande salto de Lucro',
                            xy=(df_elasticity.iloc[mid_idx]['auc'], df_elasticity.iloc[mid_idx]['profit']),
                            xytext=(df_elasticity.iloc[mid_idx]['auc'] - 0.1, df_elasticity.iloc[mid_idx]['profit']),
                            arrowprops=dict(facecolor='black', shrink=0.05, width=1.5),
                            bbox=dict(boxstyle="round,pad=0.5", fc="yellow", ec="gray", alpha=0.8),
                            fontsize=10, fontweight='bold'
                        )
                    
                    # Detalhes do Gr√°fico
                    ax.set_title(
                        f'Curva de Elasticidade: Sensibilidade do Lucro √† AUC\n'
                        f'(Threshold Fixo: {optimal_threshold:.3f} | Elasticidade: {elasticity_coef:.2f})',
                        fontsize=14, fontweight='bold', pad=20
                    )
                    
                    ax.set_xlabel('AUC-ROC (Performance do Modelo)', fontsize=12)
                    ax.set_ylabel('Lucro Estimado', fontsize=12)
                    
                    # Formata√ß√£o do Eixo Y
                    def format_currency(x, p):
                        if abs(x) >= 1e6:
                            return f'{x/1e6:.1f}M'
                        elif abs(x) >= 1e3:
                            return f'{x/1e3:.0f}k'
                        else:
                            return f'{x:.0f}'
                    
                    ax.yaxis.set_major_formatter(plt.FuncFormatter(format_currency))
                    
                    # Linha de refer√™ncia (lucro zero)
                    ax.axhline(0, color='black', linestyle=':', linewidth=1, alpha=0.5)
                    
                    # Limpeza Visual
                    ax.spines['top'].set_visible(False)
                    ax.spines['right'].set_visible(False)
                    ax.spines['left'].set_color('#cccccc')
                    ax.spines['bottom'].set_color('#cccccc')
                    ax.grid(True, alpha=0.2)
                    ax.legend(loc='best', fontsize=10)
                    
                    plt.tight_layout()
                    
                    elasticity_context = (
                        f"An√°lise de elasticidade entre AUC e lucro mantendo threshold fixo ({optimal_threshold:.3f}). "
                        f"O gr√°fico mostra como o lucro varia quando degradamos a qualidade do modelo (injetando ru√≠do). "
                        f"Coeficiente de elasticidade: {elasticity_coef:.2f} (valores > 1 indicam que lucro cresce mais r√°pido que AUC). "
                        f"Na zona de alta performance (AUC > {max_auc*0.95:.2f}), aumentar 1% de AUC gera aproximadamente "
                        f"{marginal_value_per_1pct_auc:,.0f} de lucro adicional. "
                        f"Curva {'convexa/exponencial' if elasticity_coef > 1 else 'linear' if abs(elasticity_coef - 1) < 0.3 else 'c√¥ncava'} "
                        f"indica que ganhos de performance no topo valem mais do que na base."
                    )
                    
                    logger.log_plot(
                        fig,
                        title="Curva de Elasticidade: AUC vs Lucro",
                        description="An√°lise de sensibilidade: impacto do lucro quando degradamos a AUC do modelo",
                        context_description=elasticity_context,
                        save_image=True,
                        analyze=True
                    )
                    
                    # M√©tricas e Insights
                    logger.log_metric("Coeficiente de Elasticidade", f"{elasticity_coef:.2f}")
                    logger.log_metric("Valor Marginal (1% AUC)", f"{marginal_value_per_1pct_auc:,.0f}")
                    logger.log_metric("AUC Atual", f"{current_auc:.4f}")
                    logger.log_metric("Lucro no AUC Atual", f"{current_profit:,.0f}")
                    
                    # Diagn√≥stico de Risco
                    if elasticity_coef > 2.0:
                        risk_status = "ALTO RISCO"
                        risk_msg = "Modelo muito sens√≠vel: qualquer degrada√ß√£o causar√° preju√≠zo massivo. Monitoramento cr√≠tico necess√°rio."
                    elif elasticity_coef > 1.0:
                        risk_status = "RISCO MODERADO"
                        risk_msg = "Modelo sens√≠vel: ganhos de performance no topo valem muito. Investir em melhorias pode ter ROI alto."
                    else:
                        risk_status = "RISCO BAIXO"
                        risk_msg = "Modelo robusto: degrada√ß√£o gradual n√£o causa impacto abrupto. Curva mais est√°vel."
                    
                    logger.log_insight(
                        f"**Diagn√≥stico de Elasticidade:** {risk_status}. {risk_msg} "
                        f"O coeficiente de {elasticity_coef:.2f} indica que a rela√ß√£o AUC-Lucro √© "
                        f"{'super-linear (convexa)' if elasticity_coef > 1 else 'sub-linear (c√¥ncava)' if elasticity_coef < 1 else 'linear'}. "
                        f"**ROI de Investimento:** Se melhorar o modelo em 1% de AUC custar menos que {marginal_value_per_1pct_auc:,.0f}, "
                        f"o investimento √© justificado. Caso contr√°rio, focar em estabilidade e monitoramento.",
                        "elasticity"
                    )
                    
                    # Tabela de valores marginais por faixa de AUC
                    auc_ranges = [
                        (0.50, 0.65, "Zona da Morte"),
                        (0.65, 0.80, "Zona de Crescimento"),
                        (0.80, 0.90, "Zona de Refinamento"),
                        (0.90, 1.00, "Zona de Excel√™ncia")
                    ]
                    
                    marginal_table = []
                    for auc_min, auc_max, zone_name in auc_ranges:
                        zone_data = df_elasticity[(df_elasticity['auc'] >= auc_min) & (df_elasticity['auc'] < auc_max)]
                        if len(zone_data) > 1:
                            zone_delta_profit = zone_data['profit'].max() - zone_data['profit'].min()
                            zone_delta_auc = zone_data['auc'].max() - zone_data['auc'].min()
                            zone_marginal = zone_delta_profit / (zone_delta_auc * 100) if zone_delta_auc > 0 else 0
                            marginal_table.append({
                                'Zona': zone_name,
                                'AUC Min': f"{auc_min:.2f}",
                                'AUC Max': f"{auc_max:.2f}",
                                'Valor Marginal (1% AUC)': f"{zone_marginal:,.0f}"
                            })
                    
                    if marginal_table:
                        logger.log_table("Valor Marginal por Faixa de AUC", marginal_table)
                    
                else:
                    logger.log("Simula√ß√£o de elasticidade n√£o gerou dados suficientes para an√°lise.", "warning")
                    
            else:
                logger.log("Vari√°veis necess√°rias n√£o dispon√≠veis para an√°lise de elasticidade.", "warning")
                
        except Exception as e:
            logger.log(f"Erro na an√°lise de elasticidade: {e}", "error")
            import traceback
            logger.log_code_block(traceback.format_exc(), "python")
        
        # =============================================================================
        # 12. MONITORAMENTO DE DRIFT (PSI)
        # =============================================================================
        
        logger.section("12. Monitoramento de Drift (PSI)", level=2)
        
        try:
            # ‚úÖ CORRE√á√ÉO: Garantir que calculate_psi est√° dispon√≠vel
            # Usar holdout para PSI se dispon√≠vel, sen√£o usar valida√ß√£o do treino
            train_scores_baseline = model_calibrated.predict_proba(X_train_final)[:, 1]
            
            if X_val_processed is not None and 'y_val_proba_cal' in locals():
                prod_scores_example = model_calibrated.predict_proba(X_val_processed)[:, 1]
                logger.log(f"C√°lculo de PSI usando Holdout: {len(prod_scores_example):,} amostras", "info")
            else:
                prod_scores_example = y_val_proba_cal if 'y_val_proba_cal' in locals() else y_val_pred_proba
                logger.log(f"C√°lculo de PSI usando valida√ß√£o do treino: {len(prod_scores_example):,} amostras", "warning")
            
            psi_value = calculate_psi(train_scores_baseline, prod_scores_example)
            
            logger.log_metric("PSI (Population Stability Index)", f"{psi_value:.4f}")
            
            # ‚úÖ NOVO: Plot de Distribui√ß√£o de Scores (PSI Visual)
            try:
                fig, axes = plt.subplots(1, 2, figsize=(16, 6))
                
                # Plot 1: Histograma de Distribui√ß√µes
                # Usar holdout para PSI se dispon√≠vel
                psi_scores = prod_scores_example
                psi_label = 'Holdout (Atual)' if X_val_processed is not None else 'Valida√ß√£o (Atual)'
                
                axes[0].hist(train_scores_baseline, bins=30, alpha=0.6, label='Treino (Baseline)', 
                           color='blue', density=True, edgecolor='black')
                axes[0].hist(psi_scores, bins=30, alpha=0.6, label=psi_label, 
                            color='red', density=True, edgecolor='black')
                axes[0].set_xlabel('Score Previsto', fontsize=12)
                axes[0].set_ylabel('Densidade', fontsize=12)
                axes[0].set_title(f'Distribui√ß√£o de Scores: Treino vs Valida√ß√£o (PSI={psi_value:.4f})', 
                                 fontsize=13, fontweight='bold')
                axes[0].legend(loc='best', fontsize=11)
                axes[0].grid(True, alpha=0.3)
                
                # Plot 2: KDE (Kernel Density Estimation) para visualiza√ß√£o suave
                from scipy.stats import gaussian_kde
                try:
                    kde_train = gaussian_kde(train_scores_baseline)
                    kde_prod = gaussian_kde(psi_scores)
                    x_range = np.linspace(min(min(train_scores_baseline), min(psi_scores)),
                                        max(max(train_scores_baseline), max(psi_scores)), 200)
                    axes[1].plot(x_range, kde_train(x_range), 'b-', linewidth=2, label='Treino (Baseline)', alpha=0.7)
                    axes[1].plot(x_range, kde_prod(x_range), 'r-', linewidth=2, label='Valida√ß√£o (Atual)', alpha=0.7)
                    axes[1].fill_between(x_range, kde_train(x_range), alpha=0.3, color='blue')
                    axes[1].fill_between(x_range, kde_prod(x_range), alpha=0.3, color='red')
                except:
                    # Fallback se KDE falhar
                    axes[1].hist(train_scores_baseline, bins=50, alpha=0.5, label='Treino', 
                               color='blue', density=True)
                    axes[1].hist(prod_scores_example, bins=50, alpha=0.5, label='Valida√ß√£o', 
                               color='red', density=True)
                
                axes[1].set_xlabel('Score Previsto', fontsize=12)
                axes[1].set_ylabel('Densidade', fontsize=12)
                axes[1].set_title('Distribui√ß√£o Suave (KDE): Compara√ß√£o Visual', fontsize=13, fontweight='bold')
                axes[1].legend(loc='best', fontsize=11)
                axes[1].grid(True, alpha=0.3)
                
                plt.tight_layout()
                
                psi_plot_context = (
                    f"An√°lise visual de drift usando PSI (Population Stability Index = {psi_value:.4f}). "
                    f"Esquerda: Histogramas comparando distribui√ß√µes de scores entre treino (baseline) e valida√ß√£o (atual). "
                    f"Direita: Estimativa de densidade suave (KDE) para visualiza√ß√£o mais clara das diferen√ßas. "
                    f"Quanto mais sobrepostas as distribui√ß√µes, menor o drift. "
                    f"PSI < 0.1 = Est√°vel, PSI 0.1-0.2 = Aten√ß√£o, PSI > 0.2 = Cr√≠tico (retreino necess√°rio)."
                )
                
                logger.log_plot(
                    fig,
                    title="An√°lise de Drift: Distribui√ß√£o de Scores (PSI)",
                    description="Compara√ß√£o visual de distribui√ß√µes de scores entre treino e valida√ß√£o para detectar drift",
                    context_description=psi_plot_context,
                    save_image=True,
                    analyze=True
                )
            except Exception as e:
                logger.log(f"Erro ao gerar plot de PSI: {e}", "warning")
            
            if psi_value > 0.25:
                logger.log("CR√çTICO: PSI > 0.25 - Retreino URGENTE necess√°rio!", "error")
                psi_status = "CR√çTICO"
            elif psi_value > 0.2:
                logger.log("ALERTA: PSI > 0.2 - Drift detectado. Monitorar de perto.", "warning")
                psi_status = "ALERTA"
            elif psi_value > 0.1:
                logger.log("ATEN√á√ÉO: PSI > 0.1 - Mudan√ßa leve detectada.", "warning")
                psi_status = "ATEN√á√ÉO"
            else:
                logger.log("OK: PSI < 0.1 - Distribui√ß√£o est√°vel.", "success")
                psi_status = "OK"
            
            logger.log_insight(
                f"O PSI de {psi_value:.4f} indica {'distribui√ß√£o est√°vel' if psi_value < 0.1 else 'mudan√ßa leve' if psi_value < 0.2 else 'mudan√ßa significativa'}. "
                f"Status: {psi_status}. "
                "Este valor deve ser monitorado em produ√ß√£o para detectar drift temporal.",
                "drift"
            )
            
        except NameError as e:
            logger.log(f"Erro: Fun√ß√£o calculate_psi n√£o encontrada. {e}", "error")
            import traceback
            logger.log_code_block(traceback.format_exc(), "python")
        except Exception as e:
            logger.log(f"Erro no c√°lculo de PSI: {e}", "error")
            import traceback
            logger.log_code_block(traceback.format_exc(), "python")
        
        # =============================================================================
        # 13. AN√ÅLISE DE ERROS (Error Analysis para LLM)
        # =============================================================================
        
        logger.section("13. An√°lise de Erros - Casos Reais", level=2)
        
        try:
            if 'y_val_proba_cal' in locals() and 'y_pred_optimal' in locals():
                # ‚úÖ MUDAN√áA: Usar eval_y_financial para an√°lise de erros
                eval_y_errors = eval_y_financial if 'eval_y_financial' in locals() else y_val_final
                eval_X_errors = X_val_processed if X_val_processed is not None else X_val_final
                
                # Identificar Falsos Positivos (FP): Score alto, mas pagou (y=0)
                fp_indices = np.where((y_pred_optimal == 1) & (eval_y_errors == 0))[0]
                
                # Identificar Falsos Negativos (FN): Score baixo, mas deu calote (y=1)
                fn_indices = np.where((y_pred_optimal == 0) & (eval_y_errors == 1))[0]
                
                logger.log(f"Encontrados {len(fp_indices)} Falsos Positivos e {len(fn_indices)} Falsos Negativos", "info")
                
                # Exemplos de Falsos Positivos
                if len(fp_indices) > 0:
                    logger.section("13.1. Exemplos de Falsos Positivos (Aprovamos mas Calotearam)", level=3)
                    
                    for i, idx in enumerate(fp_indices[:3], 1):  # Top 3 exemplos
                        score = y_proba_for_threshold[idx]
                        feats = eval_X_errors.iloc[idx]
                        
                        logger.log(f"**Exemplo {i}:** Score = {score:.4f} (threshold = {optimal_threshold:.4f})", "info")
                        
                        # Top 5 features com maiores valores
                        top_feats = feats.nlargest(5)
                        logger.log_table(f"Top 5 Features (Valores)", 
                                       {k: f"{v:.4f}" for k, v in top_feats.items()})
                        
                        logger.log_insight(
                            f"Este cliente foi aprovado com score {score:.4f} mas caloteou. "
                            f"As features mais altas s√£o {', '.join(top_feats.head(3).index.tolist())}. "
                            "Verifique se alguma delas est√° agindo como 'falso sinal' de bom pagador. "
                            "Poss√≠veis causas: data leakage, feature enganosa, ou padr√£o raro n√£o capturado pelo modelo.",
                            "error_analysis"
                        )
                
                # Exemplos de Falsos Negativos
                if len(fn_indices) > 0:
                    logger.section("13.2. Exemplos de Falsos Negativos (Negamos mas Pagaram)", level=3)
                    
                    for i, idx in enumerate(fn_indices[:3], 1):  # Top 3 exemplos
                        score = y_proba_for_threshold[idx]
                        feats = eval_X_errors.iloc[idx]
                        
                        logger.log(f"**Exemplo {i}:** Score = {score:.4f} (threshold = {optimal_threshold:.4f})", "info")
                        
                        # Top 5 features com menores valores (ou mais negativas)
                        top_feats = feats.nsmallest(5)
                        logger.log_table(f"Top 5 Features (Valores)", 
                                       {k: f"{v:.4f}" for k, v in top_feats.items()})
                        
                        logger.log_insight(
                            f"Este cliente foi negado com score {score:.4f} mas pagou. "
                            f"As features mais baixas s√£o {', '.join(top_feats.head(3).index.tolist())}. "
                            "Verifique se o modelo est√° sendo muito conservador ou se h√° features que est√£o "
                            "incorretamente penalizando bons pagadores. Poss√≠vel oportunidade de ajuste fino.",
                            "error_analysis"
                        )
                
                # Estat√≠sticas de erro
                eval_y_errors = eval_y_financial if 'eval_y_financial' in locals() else y_val_final
                logger.log_metric("Taxa de Falsos Positivos", f"{len(fp_indices) / len(eval_y_errors) * 100:.2f}%")
                logger.log_metric("Taxa de Falsos Negativos", f"{len(fn_indices) / len(eval_y_errors) * 100:.2f}%")
                
            else:
                logger.log("An√°lise de erros n√£o dispon√≠vel (vari√°veis necess√°rias n√£o encontradas)", "warning")
                
        except Exception as e:
            logger.log(f"Erro na an√°lise de erros: {e}", "error")
            import traceback
            logger.log_code_block(traceback.format_exc(), "python")
        
        # =============================================================================
        # FINALIZA√á√ÉO
        # =============================================================================
        
        logger.finalize()
        
        print(f"\n[OK] Pipeline executado com sucesso!")
        print(f"[INFO] Relatorio markdown salvo em: {logger.report_path}")
        print(f"[INFO] Imagens salvas em: {logger.images_dir}")
        
    except KeyboardInterrupt:
        print("\n[PARADA] Pipeline interrompido pelo usuario.")
        sys.exit(1)
    except Exception as e:
        # ‚úÖ 3. ROLLBACK AUTOM√ÅTICO em caso de falha cr√≠tica
        print(f"\n[ERRO CRITICO] Falha no pipeline: {e}")
        print("[ROLLBACK] Tentando restaurar config.yaml do backup...")
        
        if rollback_config(config_path, config_backup_path):
            print("[OK] Config.yaml restaurado. Proxima execucao usara config anterior.")
        else:
            print("[WARN] Nao foi possivel restaurar backup automaticamente.")
        
        # Log do erro no changelog se poss√≠vel
        try:
            changelog_path = Path(__file__).parent / "CHANGELOG.md"
            if changelog_path.exists():
                from datetime import datetime
                error_entry = f"\n## ERRO CRITICO - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                error_entry += f"- **Erro:** {str(e)}\n"
                error_entry += f"- **Acao:** Rollback do config.yaml executado\n---\n"
                with open(changelog_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                with open(changelog_path, 'w', encoding='utf-8') as f:
                    f.write(error_entry + content)
        except:
            pass
        
        raise  # Re-raise para que o agent_controller detecte a falha


if __name__ == "__main__":
    main()
